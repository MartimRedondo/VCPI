{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Para FID e LPIPS\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy import linalg\n",
    "import lpips  # pip install lpips\n",
    "from torchvision.models import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f60a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ ADVANCED EVALUATION - CycleGAN Real2Cartoon\")\n",
    "print(\"üìä M√©tricas: FID, LPIPS, IS, Visual Analysis\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f7015",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# CONFIGURA√á√ïES\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalConfig:\n",
    "    # Caminhos\n",
    "    MODEL_PATH = \"models_complex/cyclegan_perfection\"\n",
    "    DATASET_PATH = \"dataset/real2cartoon\"\n",
    "    RESULTS_PATH = \"evaluation_results\"\n",
    "    \n",
    "    # Par√¢metros de avalia√ß√£o\n",
    "    IMG_SIZE = 256\n",
    "    BATCH_SIZE = 8  # Maior para efici√™ncia\n",
    "    NUM_SAMPLES_FID = 1000  # Para FID robusto\n",
    "    NUM_SAMPLES_VISUAL = 25  # Para an√°lise visual\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Criar diret√≥rios\n",
    "    os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "config = EvalConfig()\n",
    "\n",
    "print(f\"üì± Device: {config.DEVICE}\")\n",
    "print(f\"üìÅ Model path: {config.MODEL_PATH}\")\n",
    "print(f\"üéØ FID samples: {config.NUM_SAMPLES_FID}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785978d6",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# DATASET PARA AVALIA√á√ÉO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationDataset(Dataset):\n",
    "    def __init__(self, root_path, mode='test', transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Caminhos para dom√≠nios A (real) e B (cartoon)\n",
    "        if mode == 'test':\n",
    "            self.path_A = Path(root_path) / 'testA'\n",
    "            self.path_B = Path(root_path) / 'testB'\n",
    "        else:\n",
    "            self.path_A = Path(root_path) / 'trainA'  # Fallback\n",
    "            self.path_B = Path(root_path) / 'trainB'\n",
    "        \n",
    "        # Listar todas as imagens\n",
    "        self.images_A = sorted(list(self.path_A.glob('*.jpg')) + list(self.path_A.glob('*.png')))\n",
    "        self.images_B = sorted(list(self.path_B.glob('*.jpg')) + list(self.path_B.glob('*.png')))\n",
    "        \n",
    "        self.length = max(len(self.images_A), len(self.images_B))\n",
    "        \n",
    "        print(f\"üìä Dataset carregado: {len(self.images_A)} reais, {len(self.images_B)} cartoons\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_A_path = self.images_A[idx % len(self.images_A)]\n",
    "        img_B_path = self.images_B[idx % len(self.images_B)]\n",
    "        \n",
    "        img_A = Image.open(img_A_path).convert('RGB')\n",
    "        img_B = Image.open(img_B_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img_A = self.transform(img_A)\n",
    "            img_B = self.transform(img_B)\n",
    "        \n",
    "        return {'A': img_A, 'B': img_B, 'path_A': str(img_A_path), 'path_B': str(img_B_path)}\n",
    "\n",
    "# Transforma√ß√µes para avalia√ß√£o\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # [-1, 1]\n",
    "])\n",
    "\n",
    "# Transforma√ß√µes para FID (necessita [0, 1])\n",
    "fid_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # InceptionV3 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # ImageNet normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a1223",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# CARREGAR MODELOS TREINADOS\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models():\n",
    "    \"\"\"Carregar modelos do checkpoint salvo\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Carregando modelos treinados...\")\n",
    "    \n",
    "    try:\n",
    "        # Carregar checkpoint\n",
    "        checkpoint_path = f\"{config.MODEL_PATH}/best_model.pth\"\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            checkpoint_path = f\"{config.MODEL_PATH}/latest_checkpoint.pth\"\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path, map_location=config.DEVICE)\n",
    "        print(f\"‚úÖ Checkpoint carregado: √©poca {checkpoint['epoch']}\")\n",
    "        \n",
    "        # DEFINIR ARQUITETURAS (copiado do notebook de treinamento)\n",
    "        class ResidualBlock(nn.Module):\n",
    "            def __init__(self, channels):\n",
    "                super(ResidualBlock, self).__init__()\n",
    "                self.block = nn.Sequential(\n",
    "                    nn.ReflectionPad2d(1),\n",
    "                    nn.Conv2d(channels, channels, 3),\n",
    "                    nn.InstanceNorm2d(channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.ReflectionPad2d(1),\n",
    "                    nn.Conv2d(channels, channels, 3),\n",
    "                    nn.InstanceNorm2d(channels)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                return x + self.block(x)\n",
    "        \n",
    "        class Generator(nn.Module):\n",
    "            def __init__(self, input_channels=3, output_channels=3, num_residual_blocks=6):\n",
    "                super(Generator, self).__init__()\n",
    "                \n",
    "                # Encoder\n",
    "                model = [\n",
    "                    nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_channels, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                ]\n",
    "                \n",
    "                # Downsampling\n",
    "                in_features = 64\n",
    "                out_features = in_features * 2\n",
    "                for _ in range(2):\n",
    "                    model += [\n",
    "                        nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    ]\n",
    "                    in_features = out_features\n",
    "                    out_features = in_features * 2\n",
    "                \n",
    "                # Residual blocks\n",
    "                for _ in range(num_residual_blocks):\n",
    "                    model += [ResidualBlock(in_features)]\n",
    "                \n",
    "                # Upsampling\n",
    "                out_features = in_features // 2\n",
    "                for _ in range(2):\n",
    "                    model += [\n",
    "                        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, out_features, kernel_size=3, stride=1, padding=0),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    ]\n",
    "                    in_features = out_features\n",
    "                    out_features = in_features // 2\n",
    "                \n",
    "                # Output layer\n",
    "                model += [\n",
    "                    nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_channels, 7),\n",
    "                    nn.Tanh()\n",
    "                ]\n",
    "                \n",
    "                self.model = nn.Sequential(*model)\n",
    "            \n",
    "            def forward(self, x):\n",
    "                return self.model(x)\n",
    "        \n",
    "        # Criar modelos\n",
    "        G_AB = Generator(num_residual_blocks=6).to(config.DEVICE)\n",
    "        G_BA = Generator(num_residual_blocks=6).to(config.DEVICE)\n",
    "        \n",
    "        # Carregar pesos\n",
    "        G_AB.load_state_dict(checkpoint['G_AB_state_dict'])\n",
    "        G_BA.load_state_dict(checkpoint['G_BA_state_dict'])\n",
    "        \n",
    "        # Modo avalia√ß√£o\n",
    "        G_AB.eval()\n",
    "        G_BA.eval()\n",
    "        \n",
    "        print(\"‚úÖ Modelos carregados e prontos para avalia√ß√£o\")\n",
    "        \n",
    "        return G_AB, G_BA, checkpoint\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar modelos: {e}\")\n",
    "        print(\"üí° Certifique-se que o treinamento foi conclu√≠do\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50381d6b",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# IMPLEMENTA√á√ÉO FID (Frechet Inception Distance)\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIDCalculator:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        # Carregar InceptionV3 pr√©-treinado\n",
    "        self.inception = inception_v3(pretrained=True, transform_input=False)\n",
    "        self.inception.fc = nn.Identity()  # Remover √∫ltima camada\n",
    "        self.inception.eval().to(device)\n",
    "        \n",
    "        print(\"‚úÖ InceptionV3 carregado para FID\")\n",
    "    \n",
    "    def get_activations(self, images):\n",
    "        \"\"\"Extrair features do InceptionV3\"\"\"\n",
    "        with torch.no_grad():\n",
    "            features = self.inception(images)\n",
    "        return features.cpu().numpy()\n",
    "    \n",
    "    def calculate_fid(self, real_images, fake_images):\n",
    "        \"\"\"Calcular FID score\"\"\"\n",
    "        \n",
    "        print(f\"üîÑ Calculando FID... Real: {len(real_images)}, Fake: {len(fake_images)}\")\n",
    "        \n",
    "        # Extrair features\n",
    "        real_features = []\n",
    "        fake_features = []\n",
    "        \n",
    "        # Process em batches\n",
    "        batch_size = 32\n",
    "        \n",
    "        for i in range(0, len(real_images), batch_size):\n",
    "            batch_real = torch.stack(real_images[i:i+batch_size]).to(self.device)\n",
    "            real_features.append(self.get_activations(batch_real))\n",
    "        \n",
    "        for i in range(0, len(fake_images), batch_size):\n",
    "            batch_fake = torch.stack(fake_images[i:i+batch_size]).to(self.device)\n",
    "            fake_features.append(self.get_activations(batch_fake))\n",
    "        \n",
    "        # Concatenar features\n",
    "        real_features = np.concatenate(real_features, axis=0)\n",
    "        fake_features = np.concatenate(fake_features, axis=0)\n",
    "        \n",
    "        # Calcular estat√≠sticas\n",
    "        mu_real = np.mean(real_features, axis=0)\n",
    "        mu_fake = np.mean(fake_features, axis=0)\n",
    "        \n",
    "        sigma_real = np.cov(real_features, rowvar=False)\n",
    "        sigma_fake = np.cov(fake_features, rowvar=False)\n",
    "        \n",
    "        # FID calculation\n",
    "        diff = mu_real - mu_fake\n",
    "        \n",
    "        # Covari√¢ncia m√©dia\n",
    "        covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
    "        \n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        \n",
    "        fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2 * covmean)\n",
    "        \n",
    "        return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbb517",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# IMPLEMENTA√á√ÉO LPIPS\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0482527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPIPSCalculator:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        # Carregar LPIPS pr√©-treinado\n",
    "        self.lpips_fn = lpips.LPIPS(net='alex').to(device)  # Usar AlexNet\n",
    "        print(\"‚úÖ LPIPS (AlexNet) carregado\")\n",
    "    \n",
    "    def calculate_lpips(self, real_images, fake_images):\n",
    "        \"\"\"Calcular LPIPS score\"\"\"\n",
    "        \n",
    "        print(f\"üîÑ Calculando LPIPS... {len(real_images)} pares\")\n",
    "        \n",
    "        lpips_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for real, fake in zip(real_images, fake_images):\n",
    "                real = real.unsqueeze(0).to(self.device)\n",
    "                fake = fake.unsqueeze(0).to(self.device)\n",
    "                \n",
    "                score = self.lpips_fn(real, fake)\n",
    "                lpips_scores.append(score.item())\n",
    "        \n",
    "        return np.mean(lpips_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153c936",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# IMPLEMENTA√á√ÉO IS (Inception Score)\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISCalculator:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        # InceptionV3 completo para classifica√ß√£o\n",
    "        self.inception = inception_v3(pretrained=True, transform_input=False)\n",
    "        self.inception.eval().to(device)\n",
    "        print(\"‚úÖ InceptionV3 carregado para IS\")\n",
    "    \n",
    "    def calculate_is(self, fake_images, splits=10):\n",
    "        \"\"\"Calcular Inception Score\"\"\"\n",
    "        \n",
    "        print(f\"üîÑ Calculando IS... {len(fake_images)} imagens\")\n",
    "        \n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(fake_images), 32):\n",
    "                batch = torch.stack(fake_images[i:i+32]).to(self.device)\n",
    "                preds = F.softmax(self.inception(batch), dim=1)\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "        \n",
    "        all_preds = np.concatenate(all_preds, axis=0)\n",
    "        \n",
    "        # Split em grupos para calcular IS\n",
    "        split_scores = []\n",
    "        for i in range(splits):\n",
    "            part = all_preds[i * len(all_preds) // splits: (i + 1) * len(all_preds) // splits]\n",
    "            \n",
    "            # P(y) marginal\n",
    "            py = np.mean(part, axis=0)\n",
    "            \n",
    "            # KL divergence\n",
    "            scores = []\n",
    "            for j in range(part.shape[0]):\n",
    "                pyx = part[j, :]\n",
    "                scores.append(np.sum(pyx * np.log(pyx / py + 1e-16)))\n",
    "            \n",
    "            split_scores.append(np.exp(np.mean(scores)))\n",
    "        \n",
    "        return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdebdac",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# GERA√á√ÉO DE AMOSTRAS PARA AVALIA√á√ÉO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d16af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_samples(G_AB, G_BA, num_samples=2000):\n",
    "    \"\"\"Gerar amostras para avalia√ß√£o FID/LPIPS/IS\"\"\"\n",
    "    \n",
    "    print(f\"üéØ Gerando {num_samples} amostras para avalia√ß√£o...\")\n",
    "    \n",
    "    # Dataset\n",
    "    eval_dataset = EvaluationDataset(config.DATASET_PATH, mode='test', transform=eval_transform)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # FID dataset (diferente normaliza√ß√£o)\n",
    "    fid_dataset = EvaluationDataset(config.DATASET_PATH, mode='test', transform=fid_transform)\n",
    "    fid_loader = DataLoader(fid_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Armazenar amostras\n",
    "    samples = {\n",
    "        'real_A': [], 'real_B': [],\n",
    "        'fake_A': [], 'fake_B': [],\n",
    "        'cycle_A': [], 'cycle_B': [],\n",
    "        'real_A_fid': [], 'real_B_fid': [],\n",
    "        'fake_A_fid': [], 'fake_B_fid': [],\n",
    "        'paths_A': [], 'paths_B': []\n",
    "    }\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Gera√ß√£o para LPIPS (normaliza√ß√£o [-1,1])\n",
    "        for batch_idx, batch in enumerate(eval_loader):\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "                \n",
    "            real_A = batch['A'].to(config.DEVICE)\n",
    "            real_B = batch['B'].to(config.DEVICE)\n",
    "            \n",
    "            # Transforma√ß√µes\n",
    "            fake_B = G_AB(real_A)  # A‚ÜíB\n",
    "            fake_A = G_BA(real_B)  # B‚ÜíA\n",
    "            \n",
    "            # Cycles\n",
    "            cycle_A = G_BA(fake_B)  # A‚ÜíB‚ÜíA\n",
    "            cycle_B = G_AB(fake_A)  # B‚ÜíA‚ÜíB\n",
    "            \n",
    "            # Armazenar (CPU para economizar VRAM)\n",
    "            batch_size = real_A.size(0)\n",
    "            for i in range(min(batch_size, num_samples - count)):\n",
    "                samples['real_A'].append(real_A[i].cpu())\n",
    "                samples['real_B'].append(real_B[i].cpu())\n",
    "                samples['fake_A'].append(fake_A[i].cpu())\n",
    "                samples['fake_B'].append(fake_B[i].cpu())\n",
    "                samples['cycle_A'].append(cycle_A[i].cpu())\n",
    "                samples['cycle_B'].append(cycle_B[i].cpu())\n",
    "                samples['paths_A'].append(batch['path_A'][i])\n",
    "                samples['paths_B'].append(batch['path_B'][i])\n",
    "                count += 1\n",
    "            \n",
    "            if batch_idx % 20 == 0:\n",
    "                progress = (count / num_samples) * 100\n",
    "                print(f\"   Progresso: {count}/{num_samples} ({progress:.1f}%)\")\n",
    "        \n",
    "        # Gera√ß√£o para FID (normaliza√ß√£o ImageNet)\n",
    "        count = 0\n",
    "        for batch_idx, batch in enumerate(fid_loader):\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "                \n",
    "            real_A = batch['A'].to(config.DEVICE)\n",
    "            real_B = batch['B'].to(config.DEVICE)\n",
    "            \n",
    "            # Converter para range [-1,1] para generators\n",
    "            real_A_gen = (real_A - 0.485) / 0.229 * 0.5  # Aproxima√ß√£o\n",
    "            real_B_gen = (real_B - 0.485) / 0.229 * 0.5\n",
    "            \n",
    "            fake_B = G_AB(real_A_gen)\n",
    "            fake_A = G_BA(real_B_gen)\n",
    "            \n",
    "            # Converter fake para ImageNet normalization\n",
    "            fake_B_fid = (fake_B * 0.229) + 0.485\n",
    "            fake_A_fid = (fake_A * 0.229) + 0.485\n",
    "            \n",
    "            batch_size = real_A.size(0)\n",
    "            for i in range(min(batch_size, num_samples - count)):\n",
    "                samples['real_A_fid'].append(real_A[i].cpu())\n",
    "                samples['real_B_fid'].append(real_B[i].cpu())\n",
    "                samples['fake_A_fid'].append(fake_A_fid[i].cpu())\n",
    "                samples['fake_B_fid'].append(fake_B_fid[i].cpu())\n",
    "                count += 1\n",
    "    \n",
    "    print(f\"‚úÖ {count} amostras geradas com sucesso!\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ed233",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# AN√ÅLISE VISUAL AVAN√áADA\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detailed_comparison_grid(samples, num_examples=8):\n",
    "    \"\"\"Criar grid de compara√ß√£o detalhado\"\"\"\n",
    "    \n",
    "    print(\"üé® Criando compara√ß√£o visual detalhada...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(num_examples, 6, figsize=(18, 3*num_examples))\n",
    "    fig.suptitle('CycleGAN Real2Cartoon - An√°lise Visual Detalhada', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['Real A', 'A‚ÜíB (Fake)', 'A‚ÜíB‚ÜíA (Cycle)', 'Real B', 'B‚ÜíA (Fake)', 'B‚ÜíA‚ÜíB (Cycle)']\n",
    "    \n",
    "    for col, header in enumerate(headers):\n",
    "        axes[0, col].set_title(header, fontweight='bold', fontsize=12)\n",
    "    \n",
    "    # Denormalize function\n",
    "    def denorm(tensor):\n",
    "        return (tensor * 0.5 + 0.5).clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "    \n",
    "    for row in range(num_examples):\n",
    "        # Real A ‚Üí Fake B ‚Üí Cycle A\n",
    "        axes[row, 0].imshow(denorm(samples['real_A'][row]))\n",
    "        axes[row, 1].imshow(denorm(samples['fake_B'][row]))\n",
    "        axes[row, 2].imshow(denorm(samples['cycle_A'][row]))\n",
    "        \n",
    "        # Real B ‚Üí Fake A ‚Üí Cycle B\n",
    "        axes[row, 3].imshow(denorm(samples['real_B'][row]))\n",
    "        axes[row, 4].imshow(denorm(samples['fake_A'][row]))\n",
    "        axes[row, 5].imshow(denorm(samples['cycle_B'][row]))\n",
    "        \n",
    "        # Remove axis\n",
    "        for col in range(6):\n",
    "            axes[row, col].set_xticks([])\n",
    "            axes[row, col].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.RESULTS_PATH}/detailed_visual_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"‚úÖ Compara√ß√£o visual salva: detailed_visual_comparison.png\")\n",
    "\n",
    "def analyze_failure_cases(samples, num_worst=5):\n",
    "    \"\"\"Analisar os piores casos\"\"\"\n",
    "    \n",
    "    print(\"üîç Analisando failure cases...\")\n",
    "    \n",
    "    # Calcular L1 loss para cada amostra\n",
    "    l1_losses_A2B = []\n",
    "    l1_losses_B2A = []\n",
    "    \n",
    "    for i in range(len(samples['real_A'])):\n",
    "        # A‚ÜíB cycle consistency\n",
    "        loss_A = F.l1_loss(samples['real_A'][i], samples['cycle_A'][i]).item()\n",
    "        l1_losses_A2B.append((loss_A, i))\n",
    "        \n",
    "        # B‚ÜíA cycle consistency  \n",
    "        loss_B = F.l1_loss(samples['real_B'][i], samples['cycle_B'][i]).item()\n",
    "        l1_losses_B2A.append((loss_B, i))\n",
    "    \n",
    "    # Pegar os piores casos\n",
    "    worst_A2B = sorted(l1_losses_A2B, reverse=True)[:num_worst]\n",
    "    worst_B2A = sorted(l1_losses_B2A, reverse=True)[:num_worst]\n",
    "    \n",
    "    # Visualizar failure cases\n",
    "    fig, axes = plt.subplots(2, num_worst*3, figsize=(15, 6))\n",
    "    fig.suptitle('Failure Cases Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    def denorm(tensor):\n",
    "        return (tensor * 0.5 + 0.5).clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # A‚ÜíB worst cases\n",
    "    for i, (loss, idx) in enumerate(worst_A2B):\n",
    "        axes[0, i*3].imshow(denorm(samples['real_A'][idx]))\n",
    "        axes[0, i*3].set_title(f'Real A\\nL1: {loss:.3f}')\n",
    "        \n",
    "        axes[0, i*3+1].imshow(denorm(samples['fake_B'][idx]))\n",
    "        axes[0, i*3+1].set_title('A‚ÜíB')\n",
    "        \n",
    "        axes[0, i*3+2].imshow(denorm(samples['cycle_A'][idx]))\n",
    "        axes[0, i*3+2].set_title('A‚ÜíB‚ÜíA')\n",
    "    \n",
    "    # B‚ÜíA worst cases\n",
    "    for i, (loss, idx) in enumerate(worst_B2A):\n",
    "        axes[1, i*3].imshow(denorm(samples['real_B'][idx]))\n",
    "        axes[1, i*3].set_title(f'Real B\\nL1: {loss:.3f}')\n",
    "        \n",
    "        axes[1, i*3+1].imshow(denorm(samples['fake_A'][idx]))\n",
    "        axes[1, i*3+1].set_title('B‚ÜíA')\n",
    "        \n",
    "        axes[1, i*3+2].imshow(denorm(samples['cycle_B'][idx]))\n",
    "        axes[1, i*3+2].set_title('B‚ÜíA‚ÜíB')\n",
    "    \n",
    "    # Remove axis\n",
    "    for i in range(2):\n",
    "        for j in range(num_worst*3):\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.RESULTS_PATH}/failure_cases_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Retornar estat√≠sticas\n",
    "    failure_stats = {\n",
    "        'worst_A2B_loss': worst_A2B[0][0],\n",
    "        'avg_A2B_loss': np.mean([loss for loss, _ in l1_losses_A2B]),\n",
    "        'worst_B2A_loss': worst_B2A[0][0],\n",
    "        'avg_B2A_loss': np.mean([loss for loss, _ in l1_losses_B2A]),\n",
    "        'worst_A2B_indices': [idx for _, idx in worst_A2B],\n",
    "        'worst_B2A_indices': [idx for _, idx in worst_B2A]\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Failure cases analisados:\")\n",
    "    print(f\"   Pior A‚ÜíB‚ÜíA loss: {failure_stats['worst_A2B_loss']:.4f}\")\n",
    "    print(f\"   Pior B‚ÜíA‚ÜíB loss: {failure_stats['worst_B2A_loss']:.4f}\")\n",
    "    \n",
    "    return failure_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66aaafb",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# FUN√á√ÉO PRINCIPAL DE AVALIA√á√ÉO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c46640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_advanced_evaluation():\n",
    "    \"\"\"Executar avalia√ß√£o completa com m√©tricas avan√ßadas\"\"\"\n",
    "    \n",
    "    print(\"üöÄ INICIANDO AVALIA√á√ÉO AVAN√áADA COMPLETA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Carregar modelos\n",
    "    G_AB, G_BA, checkpoint = load_trained_models()\n",
    "    if G_AB is None:\n",
    "        return None\n",
    "    \n",
    "    # 2. Gerar amostras\n",
    "    samples = generate_evaluation_samples(G_AB, G_BA, config.NUM_SAMPLES_FID)\n",
    "    \n",
    "    # 3. Inicializar calculadoras\n",
    "    fid_calc = FIDCalculator(config.DEVICE)\n",
    "    lpips_calc = LPIPSCalculator(config.DEVICE)\n",
    "    is_calc = ISCalculator(config.DEVICE)\n",
    "    \n",
    "    print(\"\\nüìä CALCULANDO M√âTRICAS AVAN√áADAS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 4. Calcular FID scores\n",
    "    fid_A2B = fid_calc.calculate_fid(samples['real_B_fid'], samples['fake_B_fid'])\n",
    "    fid_B2A = fid_calc.calculate_fid(samples['real_A_fid'], samples['fake_A_fid'])\n",
    "    \n",
    "    # 5. Calcular LPIPS scores\n",
    "    lpips_A2B = lpips_calc.calculate_lpips(samples['real_A'][:100], samples['fake_B'][:100])\n",
    "    lpips_B2A = lpips_calc.calculate_lpips(samples['real_B'][:100], samples['fake_A'][:100])\n",
    "    \n",
    "    # 6. Calcular IS scores\n",
    "    is_fake_A, is_std_A = is_calc.calculate_is(samples['fake_A_fid'][:1000])\n",
    "    is_fake_B, is_std_B = is_calc.calculate_is(samples['fake_B_fid'][:1000])\n",
    "    \n",
    "    # 7. An√°lises visuais\n",
    "    create_detailed_comparison_grid(samples, num_examples=8)\n",
    "    failure_stats = analyze_failure_cases(samples, num_worst=5)\n",
    "    \n",
    "    # 8. Compilar resultados\n",
    "    advanced_metrics = {\n",
    "        'metadata': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'evaluation_type': 'advanced_perceptual_analysis',\n",
    "            'num_samples_fid': len(samples['real_A_fid']),\n",
    "            'num_samples_lpips': 100,\n",
    "            'num_samples_is': 1000,\n",
    "            'model_epoch': checkpoint['epoch']\n",
    "        },\n",
    "        'fid_scores': {\n",
    "            'A_to_B': float(fid_A2B),\n",
    "            'B_to_A': float(fid_B2A),\n",
    "            'average': float((fid_A2B + fid_B2A) / 2)\n",
    "        },\n",
    "        'lpips_scores': {\n",
    "            'A_to_B': float(lpips_A2B),\n",
    "            'B_to_A': float(lpips_B2A),\n",
    "            'average': float((lpips_A2B + lpips_B2A) / 2)\n",
    "        },\n",
    "        'inception_scores': {\n",
    "            'fake_A_mean': float(is_fake_A),\n",
    "            'fake_A_std': float(is_std_A),\n",
    "            'fake_B_mean': float(is_fake_B),\n",
    "            'fake_B_std': float(is_std_B)\n",
    "        },\n",
    "        'failure_analysis': failure_stats,\n",
    "        'literature_comparison_fid': {\n",
    "            'CycleGAN_original': {'horse2zebra': 77.2, 'summer2winter': 75.8},\n",
    "            'AttentionGAN': {'selfie2anime': 71.4},\n",
    "            'UNIT': {'face_translation': 85.2},\n",
    "            'your_model_A2B': float(fid_A2B),\n",
    "            'your_model_B2A': float(fid_B2A)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 9. Salvar resultados\n",
    "    results_path = f\"{config.RESULTS_PATH}/advanced_evaluation_metrics.json\"\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(advanced_metrics, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # 10. Relat√≥rio final\n",
    "    print(\"\\nüéâ RESULTADOS FINAIS\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"üìä FID A‚ÜíB: {fid_A2B:.2f}\")\n",
    "    print(f\"üìä FID B‚ÜíA: {fid_B2A:.2f}\")\n",
    "    print(f\"üìä LPIPS A‚ÜíB: {lpips_A2B:.4f}\")\n",
    "    print(f\"üìä LPIPS B‚ÜíA: {lpips_B2A:.4f}\")\n",
    "    print(f\"üìä IS Fake A: {is_fake_A:.2f}¬±{is_std_A:.2f}\")\n",
    "    print(f\"üìä IS Fake B: {is_fake_B:.2f}¬±{is_std_B:.2f}\")\n",
    "    \n",
    "    # Interpreta√ß√£o FID\n",
    "    if fid_A2B < 50:\n",
    "        print(\"‚úÖ FID A‚ÜíB: Excelente qualidade!\")\n",
    "    elif fid_A2B < 100:\n",
    "        print(\"üëç FID A‚ÜíB: Boa qualidade\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è FID A‚ÜíB: Qualidade moderada\")\n",
    "    \n",
    "    if fid_B2A < 50:\n",
    "        print(\"‚úÖ FID B‚ÜíA: Excelente qualidade!\")\n",
    "    elif fid_B2A < 100:\n",
    "        print(\"üëç FID B‚ÜíA: Boa qualidade\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è FID B‚ÜíA: Qualidade moderada\")\n",
    "    \n",
    "    print(f\"\\nüíæ Resultados salvos em: {results_path}\")\n",
    "    print(f\"üé® Visualiza√ß√µes salvas em: {config.RESULTS_PATH}/\")\n",
    "    \n",
    "    return advanced_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90302aae",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# EXECUTAR AVALIA√á√ÉO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Verificar depend√™ncias\n",
    "    try:\n",
    "        import lpips\n",
    "        print(\"‚úÖ LPIPS dispon√≠vel\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå LPIPS n√£o encontrado. Instale com: pip install lpips\")\n",
    "    \n",
    "    # Executar avalia√ß√£o completa\n",
    "    advanced_results = run_complete_advanced_evaluation()\n",
    "    \n",
    "    if advanced_results:\n",
    "        print(\"\\nüèÜ AVALIA√á√ÉO AVAN√áADA CONCLU√çDA COM SUCESSO!\")\n",
    "        print(\"üìä M√©tricas perceptuais calculadas\")\n",
    "        print(\"üé® An√°lises visuais geradas\")\n",
    "        print(\"üîç Failure cases identificados\")\n",
    "        print(\"üíæ Resultados salvos em JSON\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Erro durante avalia√ß√£o. Verifique os modelos salvos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CG_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
