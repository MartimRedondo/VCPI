{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ffc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from torch.nn.utils import spectral_norm\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e51b8",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# RTX5070\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0cf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Precision - simples\n",
    "try:\n",
    "    from torch.amp import GradScaler, autocast  # ‚Üê NOVA SINTAXE PRIMEIRO\n",
    "    AMP_AVAILABLE = True\n",
    "    print(\"‚úÖ Mixed Precision dispon√≠vel (torch.amp)\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from torch.cuda.amp import GradScaler, autocast  # ‚Üê FALLBACK\n",
    "        AMP_AVAILABLE = True\n",
    "        print(\"‚úÖ Mixed Precision dispon√≠vel (cuda.amp)\")\n",
    "    except ImportError:\n",
    "        # Fallback simples\n",
    "        class GradScaler:\n",
    "            def __init__(self, device='cuda'): pass\n",
    "            def scale(self, loss): return loss\n",
    "            def step(self, optimizer): optimizer.step()\n",
    "            def update(self): pass\n",
    "        \n",
    "        class autocast:\n",
    "            def __init__(self, device='cuda'): pass\n",
    "            def __enter__(self): return self\n",
    "            def __exit__(self, *args): pass\n",
    "        \n",
    "        AMP_AVAILABLE = False\n",
    "        print(\"‚ö†Ô∏è Mixed Precision n√£o dispon√≠vel - usando fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d634982",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchvision.utils import save_image, make_grid\n",
    "    print(\"‚úÖ TorchVision utils dispon√≠vel\")\n",
    "except ImportError:\n",
    "    # Fallback matplotlib\n",
    "    def save_image(tensor, path, nrow=8, normalize=False, value_range=None, **kwargs):\n",
    "        if tensor.dim() == 4:\n",
    "            tensor = tensor[0]\n",
    "        img = tensor.cpu().detach().permute(1, 2, 0).numpy()\n",
    "        if normalize and value_range:\n",
    "            img = (img - value_range[0]) / (value_range[1] - value_range[0])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        plt.imsave(path, img)\n",
    "    \n",
    "    def make_grid(tensor, nrow=8, **kwargs):\n",
    "        return tensor[0] if tensor.dim() == 4 else tensor\n",
    "    \n",
    "    print(\"‚ö†Ô∏è TorchVision n√£o dispon√≠vel - usando matplotlib\")\n",
    "\n",
    "print(f\"üöÄ PyTorch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291dbc7",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# CONFIGURA√á√ïES\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigTest:\n",
    "    \"\"\"Teste r√°pido - configura√ß√£o equilibrada\"\"\"\n",
    "    \n",
    "    # Caminhos\n",
    "    DATASET_PATH = \"dataset/real2cartoon\"\n",
    "    MODEL_SAVE_PATH = \"models_complex/cyclegan_test\"\n",
    "    \n",
    "    # Par√¢metros b√°sicos\n",
    "    IMG_SIZE = 256\n",
    "    BATCH_SIZE = 1  \n",
    "    LR = 0.0001\n",
    "    BETA1 = 0.5\n",
    "    BETA2 = 0.999\n",
    "    \n",
    "    # Loss weights\n",
    "    LAMBDA_CYCLE = 20.0\n",
    "    LAMBDA_IDENTITY = 1\n",
    "    \n",
    "    # Treinamento\n",
    "    NUM_EPOCHS = 2\n",
    "    DECAY_EPOCH = 1\n",
    "    \n",
    "    # Monitoramento\n",
    "    LOG_FREQ = 50           # N√£o muito frequente\n",
    "    SAMPLE_FREQ = 200       # Samples ocasionais\n",
    "    SAVE_FREQ = 1\n",
    "    \n",
    "    # Performance equilibrada\n",
    "    NUM_WORKERS = 2        # Moderado\n",
    "    USE_AMP = AMP_AVAILABLE # Usa se dispon√≠vel\n",
    "    NUM_RESIDUAL_BLOCKS = 9\n",
    "    USE_TORCH_COMPILE = False\n",
    "    \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigProduction:\n",
    "    \n",
    "    DATASET_PATH = \"dataset/real2cartoon\"\n",
    "    MODEL_SAVE_PATH = \"models_complex/cyclegan_perfection\"\n",
    "    \n",
    "    IMG_SIZE = 256\n",
    "    BATCH_SIZE = 1  # REDUZIR para 1\n",
    "    \n",
    "    # LEARNING RATES BALANCEADOS\n",
    "    LR_G = 1e-4      # Generator mais lento\n",
    "    LR_D = 4e-4      # Discriminators 4x mais r√°pidos\n",
    "    \n",
    "    BETA1 = 0.0      # CR√çTICO para TTUR\n",
    "    BETA2 = 0.9     \n",
    "    \n",
    "    # PESOS REBALANCEADOS\n",
    "    LAMBDA_CYCLE = 50.0     # LSGAN precisa pesos maiores\n",
    "    LAMBDA_IDENTITY = 25.0  # Metade do cycle\n",
    "    \n",
    "    NUM_EPOCHS = 50\n",
    "    DECAY_EPOCH = 25\n",
    "    \n",
    "    LOG_FREQ = 10\n",
    "    SAMPLE_FREQ = 200\n",
    "    SAVE_FREQ = 5\n",
    "    \n",
    "    NUM_WORKERS = 0  # Reduzir para debug\n",
    "    USE_AMP = False  # DESABILITAR AMP\n",
    "    NUM_RESIDUAL_BLOCKS = 6\n",
    "    \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = ConfigTest()  # Use ConfigProduction() para treinamento completo\n",
    "config = ConfigProduction()  # Use esta linha para produ√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cuda_optimizations():\n",
    "    \"\"\"Aplicar otimiza√ß√µes CUDA seguras\"\"\"\n",
    "    try:\n",
    "        # Otimiza√ß√µes b√°sicas\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"‚úÖ Otimiza√ß√µes CUDA aplicadas com seguran√ßa\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao aplicar otimiza√ß√µes: {e}\")\n",
    "\n",
    "apply_cuda_optimizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6052fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üîç GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ VRAM Total: {total_memory:.1f}GB\")\n",
    "        print(f\"üìä Batch configurado: {config.BATCH_SIZE}\")\n",
    "        \n",
    "        # Estimativa de uso de VRAM\n",
    "        estimated_vram = config.BATCH_SIZE * 256 * 256 * 3 * 4 * 8 / 1e9  # Rough estimate\n",
    "        vram_percent = (estimated_vram / total_memory) * 100\n",
    "        \n",
    "        print(f\"üìà VRAM estimado: {estimated_vram:.1f}GB ({vram_percent:.1f}%)\")\n",
    "        \n",
    "        if vram_percent < 80:\n",
    "            print(\"‚úÖ Configura√ß√£o segura para VRAM\")\n",
    "        elif vram_percent < 90:\n",
    "            print(\"‚ö†Ô∏è Configura√ß√£o no limite - monitore a VRAM\")\n",
    "        else:\n",
    "            print(\"‚ùå Configura√ß√£o pode causar out-of-memory\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå CUDA n√£o dispon√≠vel\")\n",
    "\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9647e3",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# DATASET PERSONALIZADO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANDataset(Dataset):\n",
    "    def __init__(self, root_path, mode='train', transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Caminhos para dom√≠nios A (real) e B (cartoon)\n",
    "        if mode == 'train':\n",
    "            self.path_A = Path(root_path) / 'trainA'\n",
    "            self.path_B = Path(root_path) / 'trainB'\n",
    "        else:\n",
    "            self.path_A = Path(root_path) / 'testA'\n",
    "            self.path_B = Path(root_path) / 'testB'\n",
    "        \n",
    "        # Listar todas as imagens\n",
    "        self.images_A = sorted(list(self.path_A.glob('*.jpg')) + list(self.path_A.glob('*.png')))\n",
    "        self.images_B = sorted(list(self.path_B.glob('*.jpg')) + list(self.path_B.glob('*.png')))\n",
    "        \n",
    "        self.length = max(len(self.images_A), len(self.images_B))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Usar m√≥dulo para evitar index out of bounds\n",
    "        img_A_path = self.images_A[idx % len(self.images_A)]\n",
    "        img_B_path = self.images_B[idx % len(self.images_B)]\n",
    "        \n",
    "        img_A = Image.open(img_A_path).convert('RGB')\n",
    "        img_B = Image.open(img_B_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img_A = self.transform(img_A)\n",
    "            img_B = self.transform(img_B)\n",
    "        \n",
    "        return {'A': img_A, 'B': img_B}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ce7be",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# TRANSFORMA√á√ïES\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # [-1, 1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e698b87",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# BLOCOS DE CONSTRU√á√ÉO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ddd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, 3),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, 3),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e50a5b",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# GERADOR (ResNet-based)\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, num_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        if num_residual_blocks is None:\n",
    "            num_residual_blocks = config.NUM_RESIDUAL_BLOCKS\n",
    "        \n",
    "        # Encoder\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_channels, 64, 7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        \n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "        \n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "        \n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=1, padding=0),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "        \n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6119c05",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# DISCRIMINADOR (PatchGAN)\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89725d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            layers = []\n",
    "            conv = spectral_norm(nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1))\n",
    "            layers.append(conv)\n",
    "            \n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(input_channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            spectral_norm(nn.Linear(512, 1))  # ‚Üê S√ì UMA LAYER\n",
    "        )\n",
    "            \n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db090a",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# INICIALIZA√á√ÉO DOS MODELOS\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c792fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    \"\"\"Inicializa√ß√£o de pesos simplificada\"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        try:\n",
    "            torch.nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "        except:\n",
    "            pass\n",
    "    elif classname.find('BatchNorm2d') != -1 or classname.find('InstanceNorm2d') != -1:\n",
    "        try:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar modelos\n",
    "print(\"üîß Criando modelos...\")\n",
    "G_AB = Generator(num_residual_blocks=config.NUM_RESIDUAL_BLOCKS).to(config.DEVICE)\n",
    "G_BA = Generator(num_residual_blocks=config.NUM_RESIDUAL_BLOCKS).to(config.DEVICE)\n",
    "D_A = Discriminator().to(config.DEVICE)\n",
    "D_B = Discriminator().to(config.DEVICE)\n",
    "\n",
    "# Inicializar pesos\n",
    "print(\"üîß Inicializando pesos...\")\n",
    "try:\n",
    "    G_AB.apply(weights_init_normal)\n",
    "    G_BA.apply(weights_init_normal)\n",
    "    D_A.apply(weights_init_normal)\n",
    "    D_B.apply(weights_init_normal)\n",
    "    print(\"‚úÖ Pesos inicializados com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Inicializa√ß√£o customizada falhou: {e}\")\n",
    "    print(\"üîÑ Usando inicializa√ß√£o padr√£o PyTorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60839bdb",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# LOSS FUNCTIONS\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf22d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANLoss:\n",
    "    def __init__(self):\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def adversarial_loss(self, pred, target_is_real):\n",
    "        if target_is_real:\n",
    "            target = torch.ones_like(pred) * 0.95\n",
    "        else:\n",
    "            target = torch.zeros_like(pred) + 0.05\n",
    "        return self.bce_loss(pred, target)\n",
    "    \n",
    "    # ‚Üê NOVA FUN√á√ÉO LSGAN (ADICIONAR)\n",
    "    def adversarial_loss_lsgan(self, pred, target_is_real):\n",
    "        if target_is_real:\n",
    "            target = torch.ones_like(pred) * 0.9  # Em vez de 1.0\n",
    "        else:\n",
    "            target = torch.zeros_like(pred) + 0.1  # Em vez de 0.0\n",
    "        return 0.5 * self.mse_loss(pred, target)\n",
    "    \n",
    "    def adversarial_loss_smooth(self, pred, target_is_real):\n",
    "        \"\"\"Loss mais suave especificamente para D_B super-expert\"\"\"\n",
    "        if target_is_real:\n",
    "            target = torch.ones_like(pred) * 0.75  # ‚Üê Menos confiante\n",
    "        else:\n",
    "            target = torch.zeros_like(pred) + 0.25  # ‚Üê Menos confiante\n",
    "        return self.bce_loss(pred, target)\n",
    "    \n",
    "    def cycle_consistency_loss(self, real, cycled):\n",
    "        return self.l1_loss(real, cycled)\n",
    "    \n",
    "    def identity_loss(self, real, same):\n",
    "        return self.l1_loss(real, same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591fe295",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# OTIMIZADORES\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086453cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_AB.parameters(), G_BA.parameters()),\n",
    "    lr=config.LR_G, betas=(config.BETA1, config.BETA2)\n",
    ")\n",
    "\n",
    "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=config.LR_D, betas=(config.BETA1, config.BETA2))\n",
    "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=config.LR_D, betas=(config.BETA1, config.BETA2))\n",
    "\n",
    "# Learning rate schedulers\n",
    "def lambda_rule(epoch):\n",
    "    lr_l = 1.0 - max(0, epoch + 1 - config.DECAY_EPOCH) / (config.NUM_EPOCHS - config.DECAY_EPOCH + 1)\n",
    "    return lr_l\n",
    "\n",
    "scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_rule)\n",
    "scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_rule)\n",
    "scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6f44f",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# BUFFER PARA IMAGENS FAKE\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d987512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBuffer:\n",
    "    def __init__(self, buffer_size=50):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = []\n",
    "    \n",
    "    def query(self, images):\n",
    "        if self.buffer_size == 0:\n",
    "            return images\n",
    "        \n",
    "        images_cloned = images.detach().clone()\n",
    "        return_images = []\n",
    "        \n",
    "        for image in images_cloned:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if len(self.buffer) < self.buffer_size:\n",
    "                self.buffer.append(image.clone())\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = np.random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    i = np.random.randint(0, self.buffer_size)\n",
    "                    return_images.append(self.buffer[i].clone())\n",
    "                    self.buffer[i] = image.clone()\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        \n",
    "        return torch.cat(return_images, 0)\n",
    "\n",
    "fake_A_buffer = ImageBuffer()\n",
    "fake_B_buffer = ImageBuffer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88923483",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USE_AMP:\n",
    "    try:\n",
    "        if AMP_AVAILABLE:\n",
    "            # ARROZ\n",
    "            try:\n",
    "                scalers = {\n",
    "                    'G': GradScaler(), \n",
    "                    'D_A': GradScaler(), \n",
    "                    'D_B': GradScaler() \n",
    "                }\n",
    "                print(\"‚úÖ Mixed Precision (nova sintaxe) configurado\")\n",
    "            except:\n",
    "                # Fallback para sintaxe antiga\n",
    "                scalers = {\n",
    "                    'G': GradScaler(),\n",
    "                    'D_A': GradScaler(),\n",
    "                    'D_B': GradScaler()\n",
    "                }\n",
    "                print(\"‚úÖ Mixed Precision (sintaxe antiga) configurado\")\n",
    "        else:\n",
    "            config.USE_AMP = False\n",
    "            print(\"‚ùå Mixed Precision desabilitado\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao configurar AMP: {e}\")\n",
    "        config.USE_AMP = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc8e8b",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# DATASET E DATALOADERS\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CycleGANDataset(config.DATASET_PATH, mode='train', transform=transform)\n",
    "test_dataset = CycleGANDataset(config.DATASET_PATH, mode='test', transform=transform)\n",
    "\n",
    "# DataLoader otimizado mas seguro\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True,               \n",
    "    #persistent_workers=True,\n",
    "    #prefetch_factor=2,  # Reduzido para estabilidade\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=config.NUM_WORKERS//2,  # Menos workers para test\n",
    "    pin_memory=True,\n",
    "    # prefetch_factor=1\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} amostras\")\n",
    "print(f\"Test dataset: {len(test_dataset)} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc16ec",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# FUN√á√ïES DE VISUALIZA√á√ÉO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample_images(real_A, real_B, fake_A, fake_B, cycle_A, cycle_B, epoch, batch_i):\n",
    "    \"\"\"Salvamento otimizado usando torchvision.utils\"\"\"\n",
    "    \n",
    "    os.makedirs(f\"{config.MODEL_SAVE_PATH}/images\", exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Criar grid de 6 imagens - muito mais eficiente que matplotlib\n",
    "        imgs = torch.cat([\n",
    "            real_A[0:1], fake_B[0:1], cycle_A[0:1],\n",
    "            real_B[0:1], fake_A[0:1], cycle_B[0:1]\n",
    "        ], dim=0)\n",
    "        \n",
    "        grid = make_grid(imgs, nrow=3, normalize=True, value_range=(-1, 1), padding=2)\n",
    "        save_path = f\"{config.MODEL_SAVE_PATH}/images/epoch_{epoch:03d}_batch_{batch_i:04d}.png\"\n",
    "        save_image(grid, save_path)\n",
    "        \n",
    "        # Log apenas no primeiro batch de cada √©poca para n√£o poluir console\n",
    "        if batch_i == 0:\n",
    "            print(f\"    üíæ Sample salvo: epoch_{epoch:03d}_batch_{batch_i:04d}.png\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # N√£o parar o treinamento por erro de salvamento de imagem\n",
    "        print(f\"    ‚ö†Ô∏è Erro ao salvar imagem: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9440ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_robust(epoch, G_AB, G_BA, D_A, D_B, optimizer_G, optimizer_D_A, optimizer_D_B, \n",
    "                          scheduler_G, scheduler_D_A, scheduler_D_B, history, best_loss=None):\n",
    "    \"\"\"Sistema robusto de checkpoints\"\"\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(config.MODEL_SAVE_PATH, exist_ok=True)\n",
    "        \n",
    "        # Calcular se √© o melhor modelo\n",
    "        current_loss = history['G_loss'][-1] if history['G_loss'] else float('inf')\n",
    "        if best_loss is None:\n",
    "            best_loss = float('inf')\n",
    "        is_best = current_loss < best_loss\n",
    "        \n",
    "        checkpoint_data = {\n",
    "            'epoch': epoch,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'best_loss': min(best_loss, current_loss),\n",
    "            'G_AB_state_dict': G_AB.state_dict(),\n",
    "            'G_BA_state_dict': G_BA.state_dict(),\n",
    "            'D_A_state_dict': D_A.state_dict(),\n",
    "            'D_B_state_dict': D_B.state_dict(),\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_A_state_dict': optimizer_D_A.state_dict(),\n",
    "            'optimizer_D_B_state_dict': optimizer_D_B.state_dict(),\n",
    "            'scheduler_G_state_dict': scheduler_G.state_dict(),\n",
    "            'scheduler_D_A_state_dict': scheduler_D_A.state_dict(),\n",
    "            'scheduler_D_B_state_dict': scheduler_D_B.state_dict(),\n",
    "            'history': history,\n",
    "            'config_snapshot': {\n",
    "                'batch_size': config.BATCH_SIZE,\n",
    "                'lr_g': config.LR_G,\n",
    "                'lr_d': config.LR_D,\n",
    "                'lambda_cycle': config.LAMBDA_CYCLE,\n",
    "                'lambda_identity': config.LAMBDA_IDENTITY,\n",
    "                'num_epochs': config.NUM_EPOCHS,\n",
    "                'use_amp': config.USE_AMP\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Salvar checkpoint atual\n",
    "        checkpoint_path = f\"{config.MODEL_SAVE_PATH}/checkpoint_epoch_{epoch:03d}.pth\"\n",
    "        torch.save(checkpoint_data, checkpoint_path)\n",
    "        \n",
    "        # Sempre salvar como √∫ltimo\n",
    "        torch.save(checkpoint_data, f\"{config.MODEL_SAVE_PATH}/latest_checkpoint.pth\")\n",
    "        \n",
    "        # Salvar como melhor se for o caso\n",
    "        if is_best:\n",
    "            torch.save(checkpoint_data, f\"{config.MODEL_SAVE_PATH}/best_model.pth\")\n",
    "            print(f\"    üíé Novo melhor modelo! G Loss: {current_loss:.4f}\")\n",
    "        \n",
    "        print(f\"    üíæ Checkpoint salvo: epoch_{epoch:03d}.pth\")\n",
    "        \n",
    "        # Limpeza autom√°tica (manter apenas √∫ltimos 3)\n",
    "        try:\n",
    "            checkpoint_dir = Path(config.MODEL_SAVE_PATH)\n",
    "            checkpoints = []\n",
    "            for f in checkpoint_dir.glob(\"checkpoint_epoch_*.pth\"):\n",
    "                try:\n",
    "                    epoch_num = int(f.stem.split('_')[-1])\n",
    "                    checkpoints.append((epoch_num, f))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            checkpoints.sort(key=lambda x: x[0])\n",
    "            while len(checkpoints) > 3:\n",
    "                _, old_file = checkpoints.pop(0)\n",
    "                old_file.unlink()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return min(best_loss, current_loss)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Erro ao salvar checkpoint: {e}\")\n",
    "        return best_loss if best_loss is not None else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_load_checkpoint():\n",
    "    \"\"\"Tentar carregar checkpoint existente\"\"\"\n",
    "    latest_path = f\"{config.MODEL_SAVE_PATH}/latest_checkpoint.pth\"\n",
    "    \n",
    "    if os.path.exists(latest_path):\n",
    "        try:\n",
    "            print(f\"üìÇ Checkpoint encontrado: {latest_path}\")\n",
    "            # REMOVER: choice = input(...)\n",
    "            # REMOVER: if choice in ['y', 'yes']:\n",
    "        \n",
    "            checkpoint = torch.load(latest_path, map_location=config.DEVICE)\n",
    "            print(f\"‚úÖ Checkpoint da √©poca {checkpoint['epoch']} carregado automaticamente\")\n",
    "            return checkpoint\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar checkpoint: {e}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76658b04",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# LOOP DE TREINAMENTO\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1463e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_discriminator_noise(images):\n",
    "    random_noise = 0.05 + 0.10 * torch.rand(1).item()\n",
    "    noise = torch.randn_like(images) * random_noise\n",
    "    return images + noise\n",
    "\n",
    "def ultra_stable_train_step(real_A, real_B, models, optimizers, criterion, config, batch_i):\n",
    "    \"\"\"Training step com 5 D-steps para ressuscitar discriminadores\"\"\"\n",
    "    \n",
    "    G_AB, G_BA, D_A, D_B = models['G_AB'], models['G_BA'], models['D_A'], models['D_B']\n",
    "    opt_G, opt_D_A, opt_D_B = optimizers['G'], optimizers['D_A'], optimizers['D_B']\n",
    "    \n",
    "    if batch_i % 2 == 0:  # ‚Üê S√ì TREINAR D a cada 2 batches\n",
    "        \n",
    "        # DISCRIMINADOR A\n",
    "        opt_D_A.zero_grad()\n",
    "        pred_real_A = D_A(real_A)\n",
    "        loss_D_real_A = criterion.adversarial_loss_lsgan(pred_real_A, True)  # ‚Üê LSGAN\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_A = G_BA(real_B)\n",
    "        \n",
    "        pred_fake_A = D_A(fake_A.detach())\n",
    "        loss_D_fake_A = criterion.adversarial_loss_lsgan(pred_fake_A, False)\n",
    "        \n",
    "        loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5\n",
    "        loss_D_A.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(D_A.parameters(), max_norm=1.0)\n",
    "        opt_D_A.step()\n",
    "        \n",
    "        # DISCRIMINADOR B\n",
    "        opt_D_B.zero_grad()\n",
    "        pred_real_B = D_B(add_discriminator_noise(real_B))\n",
    "        loss_D_real_B = criterion.adversarial_loss_lsgan(pred_real_B, True)  # ‚Üê LSGAN\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_B = G_AB(real_A)\n",
    "        \n",
    "        pred_fake_B = D_B(add_discriminator_noise(fake_B.detach()))\n",
    "        loss_D_fake_B = criterion.adversarial_loss_lsgan(pred_fake_B, False)\n",
    "        \n",
    "        loss_D_B = (loss_D_real_B + loss_D_fake_B) * 0.5\n",
    "        loss_D_B.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(D_B.parameters(), max_norm=1.0)\n",
    "        opt_D_B.step()\n",
    "    \n",
    "    else:\n",
    "        # ‚úÖ QUANDO N√ÉO TREINAR D, AINDA PRECISAMOS DAS PREDI√á√ïES PARA LOGS:\n",
    "        with torch.no_grad():\n",
    "            fake_A = G_BA(real_B)\n",
    "            fake_B = G_AB(real_A)\n",
    "            pred_real_A = D_A(real_A)\n",
    "            pred_fake_A = D_A(fake_A)\n",
    "            pred_real_B = D_B(real_B) \n",
    "            pred_fake_B = D_B(fake_B)\n",
    "            loss_D_A = torch.tensor(0.0)  # ‚Üê Para logs\n",
    "            loss_D_B = torch.tensor(0.0)  # ‚Üê Para logs\n",
    "\n",
    "    \n",
    "    # =================\n",
    "    # TREINAR GERADORES - APENAS 1 STEP\n",
    "    # ==================\n",
    "    \n",
    "    opt_G.zero_grad()\n",
    "    \n",
    "    # Generate fresh fakes\n",
    "    fake_B = G_AB(real_A)\n",
    "    fake_A = G_BA(real_B)\n",
    "    \n",
    "    # Adversarial loss (peso MUITO reduzido)\n",
    "    pred_fake_B = D_B(fake_B)\n",
    "    loss_GAN_AB = criterion.adversarial_loss_lsgan(pred_fake_B, True)  # ‚Üê LSGAN\n",
    "    \n",
    "    pred_fake_A = D_A(fake_A)\n",
    "    loss_GAN_BA = criterion.adversarial_loss_lsgan(pred_fake_A, True)  # ‚Üê LSGAN\n",
    "    \n",
    "    loss_GAN = (loss_GAN_AB + loss_GAN_BA) * 1.0  # ‚Üê PESO MUITO BAIXO\n",
    "    \n",
    "    # Cycle loss (DOMINANTE)\n",
    "    cycle_A = G_BA(fake_B)\n",
    "    cycle_B = G_AB(fake_A)\n",
    "    \n",
    "    loss_cycle_A = criterion.cycle_consistency_loss(real_A, cycle_A)\n",
    "    loss_cycle_B = criterion.cycle_consistency_loss(real_B, cycle_B)\n",
    "    loss_cycle = (loss_cycle_A + loss_cycle_B) * 0.5\n",
    "    \n",
    "    # Identity loss (quase zero)\n",
    "    if config.LAMBDA_IDENTITY > 0:\n",
    "        identity_A = G_BA(real_A)\n",
    "        identity_B = G_AB(real_B)\n",
    "        loss_identity_A = criterion.identity_loss(real_A, identity_A)\n",
    "        loss_identity_B = criterion.identity_loss(real_B, identity_B)\n",
    "        loss_identity = (loss_identity_A + loss_identity_B) * 0.5\n",
    "    else:\n",
    "        loss_identity = 0\n",
    "    \n",
    "    # Total generator loss - CYCLE DOMINA COMPLETAMENTE\n",
    "    loss_G = (loss_GAN + \n",
    "         config.LAMBDA_CYCLE * loss_cycle + \n",
    "         config.LAMBDA_IDENTITY * loss_identity)\n",
    "    \n",
    "    loss_G.backward()\n",
    "    \n",
    "    # Gradient clipping agressivo para geradores\n",
    "    torch.nn.utils.clip_grad_norm_(G_AB.parameters(), max_norm=1.0)\n",
    "    torch.nn.utils.clip_grad_norm_(G_BA.parameters(), max_norm=1.0)\n",
    "    \n",
    "    opt_G.step() \n",
    "\n",
    "    G_AB.eval()  # ‚Üê MODO EVAL\n",
    "    G_BA.eval()  # ‚Üê MODO EVAL\n",
    "\n",
    "    with torch.no_grad():\n",
    "        display_fake_B = G_AB(real_A)  # ‚Üê Limpo, s√≥ para visualizar\n",
    "        display_fake_A = G_BA(real_B)  # ‚Üê Limpo, s√≥ para visualizar\n",
    "\n",
    "    # ADICIONAR ESTAS 2 LINHAS:\n",
    "    G_AB.train()  # ‚Üê VOLTAR PARA TRAIN\n",
    "    G_BA.train()  # ‚Üê VOLTAR PARA TRAIN\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'loss_G': loss_G.item(),\n",
    "        'loss_D_A': loss_D_A.item(),\n",
    "        'loss_D_B': loss_D_B.item(),\n",
    "        'loss_cycle': loss_cycle.item(),\n",
    "        'loss_GAN': loss_GAN.item(),\n",
    "        'pred_real_A': pred_real_A.mean().item(),\n",
    "        'pred_fake_A': pred_fake_A.mean().item(),\n",
    "        'pred_real_B': pred_real_B.mean().item(),\n",
    "        'pred_fake_B': pred_fake_B.mean().item(),\n",
    "        'fake_A': display_fake_A, \n",
    "        'fake_B': display_fake_B, \n",
    "        'cycle_A': cycle_A.detach(), \n",
    "        'cycle_B': cycle_B.detach()  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98600696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cyclegan():\n",
    "    print(\"üöÄ Iniciando treinamento CycleGAN MELHORADO\")\n",
    "    print(f\"üìä Configura√ß√£o: Œª_cycle={config.LAMBDA_CYCLE}, Œª_identity={config.LAMBDA_IDENTITY}\")\n",
    "    \n",
    "    criterion = CycleGANLoss()\n",
    "\n",
    "    # Criar diret√≥rios\n",
    "    os.makedirs(config.MODEL_SAVE_PATH, exist_ok=True)\n",
    "    os.makedirs(f\"{config.MODEL_SAVE_PATH}/images\", exist_ok=True)\n",
    "    \n",
    "    # Tentar carregar checkpoint\n",
    "    checkpoint = try_load_checkpoint()\n",
    "    start_epoch = checkpoint['epoch'] + 1 if checkpoint else 0\n",
    "    \n",
    "    # Hist√≥rico de losses\n",
    "    history = {\n",
    "        'G_loss': [], 'D_A_loss': [], 'D_B_loss': [],\n",
    "        'cycle_loss': [], 'adv_loss': [], 'epoch_times': []\n",
    "    }\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # Carregar estados do checkpoint se existir\n",
    "    if checkpoint:\n",
    "        G_AB.load_state_dict(checkpoint['G_AB_state_dict'])\n",
    "        G_BA.load_state_dict(checkpoint['G_BA_state_dict'])\n",
    "        D_A.load_state_dict(checkpoint['D_A_state_dict'])\n",
    "        D_B.load_state_dict(checkpoint['D_B_state_dict'])\n",
    "        \n",
    "        optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "        optimizer_D_A.load_state_dict(checkpoint['optimizer_D_A_state_dict'])\n",
    "        optimizer_D_B.load_state_dict(checkpoint['optimizer_D_B_state_dict'])\n",
    "        \n",
    "        scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])\n",
    "        scheduler_D_A.load_state_dict(checkpoint['scheduler_D_A_state_dict'])\n",
    "        scheduler_D_B.load_state_dict(checkpoint['scheduler_D_B_state_dict'])\n",
    "        \n",
    "        history = checkpoint['history']\n",
    "        best_loss = checkpoint.get('best_loss', float('inf'))\n",
    "        \n",
    "        print(f\"üìÇ Checkpoint carregado - continuando da √©poca {start_epoch}\")\n",
    "    \n",
    "    # Mixed Precision\n",
    "    if config.USE_AMP:\n",
    "        #ARROZ\n",
    "        scalers = {\n",
    "            'G': GradScaler(),\n",
    "            'D_A': GradScaler(),\n",
    "            'D_B': GradScaler()\n",
    "        }\n",
    "    \n",
    "    # LOOP PRINCIPAL COM TRATAMENTO DE ERROS\n",
    "    print(f\"\\nüé¨ INICIANDO TREINAMENTO - √âpocas {start_epoch} a {config.NUM_EPOCHS-1}\")\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(start_epoch, config.NUM_EPOCHS):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # Losses da √©poca\n",
    "            epoch_G_loss = 0\n",
    "            epoch_D_A_loss = 0\n",
    "            epoch_D_B_loss = 0\n",
    "            epoch_cycle_loss = 0\n",
    "            epoch_adv_loss = 0\n",
    "            \n",
    "            for batch_i, batch in enumerate(train_loader):\n",
    "                real_B = batch['B'].to(config.DEVICE, non_blocking=True)\n",
    "                real_A = batch['A'].to(config.DEVICE, non_blocking=True)\n",
    "\n",
    "                # Criar dicion√°rios para organizar\n",
    "                models = {\n",
    "                    'G_AB': G_AB,\n",
    "                    'G_BA': G_BA, \n",
    "                    'D_A': D_A,\n",
    "                    'D_B': D_B\n",
    "                }\n",
    "\n",
    "                optimizers = {\n",
    "                    'G': optimizer_G,\n",
    "                    'D_A': optimizer_D_A,\n",
    "                    'D_B': optimizer_D_B\n",
    "                }\n",
    "\n",
    "                # CHAMAR A FUN√á√ÉO CORRIGIDA\n",
    "                results = ultra_stable_train_step(\n",
    "                    real_A, real_B, models, optimizers, criterion, config, batch_i\n",
    "            )\n",
    "\n",
    "                # Acumular losses e m√©tricas\n",
    "                epoch_G_loss += results['loss_G']\n",
    "                epoch_D_A_loss += results['loss_D_A']\n",
    "                epoch_D_B_loss += results['loss_D_B']\n",
    "                epoch_cycle_loss += results['loss_cycle']\n",
    "                epoch_adv_loss += results['loss_GAN']\n",
    "\n",
    "                # LOGGING MELHORADO COM STATUS DOS DISCRIMINADORES\n",
    "                if batch_i % config.LOG_FREQ == 0:\n",
    "                    progress = ((epoch * len(train_loader) + batch_i) / (config.NUM_EPOCHS * len(train_loader))) * 100\n",
    "\n",
    "                    # VRAM info\n",
    "                    if torch.cuda.is_available():\n",
    "                        vram_used = torch.cuda.memory_allocated() / 1e9\n",
    "                        vram_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "                        vram_percent = (vram_used / vram_total) * 100\n",
    "                    else:\n",
    "                        vram_percent = 0\n",
    "\n",
    "                    # STATUS DOS DISCRIMINADORES - CRUCIAL!\n",
    "                    d_status = \"üî•\" if (results['loss_D_A'] > 0.1 and results['loss_D_B'] > 0.1) else \"üíÄ\"\n",
    "\n",
    "                    print(f\"E{epoch:03d}-B{batch_i:04d} ({progress:.1f}%) {d_status} | \"\n",
    "                          f\"G:{results['loss_G']:.4f} Cyc:{results['loss_cycle']:.4f} | \"\n",
    "                          f\"D_A:{results['loss_D_A']:.4f} D_B:{results['loss_D_B']:.4f} | \"\n",
    "                          f\"Pred: rA:{results['pred_real_A']:.2f} fA:{results['pred_fake_A']:.2f} \"\n",
    "                          f\"rB:{results['pred_real_B']:.2f} fB:{results['pred_fake_B']:.2f} | \"\n",
    "                          f\"VRAM:{vram_percent:.1f}%\")\n",
    "\n",
    "                # Salvar imagens de amostra\n",
    "                if batch_i % config.SAMPLE_FREQ == 0:\n",
    "                    save_sample_images(\n",
    "                        real_A, real_B, \n",
    "                        results['fake_A'], results['fake_B'], \n",
    "                        results['cycle_A'], results['cycle_B'], \n",
    "                        epoch, batch_i\n",
    "                    )\n",
    "\n",
    "            # Atualizar learning rate\n",
    "            scheduler_G.step()\n",
    "            scheduler_D_A.step()\n",
    "            scheduler_D_B.step()\n",
    "            \n",
    "            # Fim da √©poca\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            \n",
    "            # Salvar m√©dias das losses da √©poca\n",
    "            history['G_loss'].append(epoch_G_loss / len(train_loader))\n",
    "            history['D_A_loss'].append(epoch_D_A_loss / len(train_loader))\n",
    "            history['D_B_loss'].append(epoch_D_B_loss / len(train_loader))\n",
    "            history['cycle_loss'].append(epoch_cycle_loss / len(train_loader))\n",
    "            history['adv_loss'].append(epoch_adv_loss / len(train_loader))\n",
    "            history['epoch_times'].append(epoch_time)\n",
    "            \n",
    "            # Log da √©poca\n",
    "            current_lr = scheduler_G.get_last_lr()[0]\n",
    "            avg_G_loss = epoch_G_loss / len(train_loader)\n",
    "            avg_cycle_loss = epoch_cycle_loss / len(train_loader)\n",
    "            \n",
    "            print(f\"\\n‚úÖ √âPOCA {epoch}/{config.NUM_EPOCHS-1} conclu√≠da em {epoch_time:.1f}s\")\n",
    "            print(f\"üìä G:{avg_G_loss:.4f} | Cycle:{avg_cycle_loss:.4f} | LR:{current_lr:.6f}\")\n",
    "            \n",
    "            # Salvar checkpoint com sistema robusto\n",
    "            if epoch % config.SAVE_FREQ == 0 or epoch == config.NUM_EPOCHS - 1:\n",
    "                best_loss = save_checkpoint_robust(\n",
    "                    epoch, G_AB, G_BA, D_A, D_B, \n",
    "                    optimizer_G, optimizer_D_A, optimizer_D_B,\n",
    "                    scheduler_G, scheduler_D_A, scheduler_D_B,\n",
    "                    history, best_loss\n",
    "                )\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è Treinamento interrompido pelo usu√°rio\")\n",
    "        save_checkpoint_robust(\n",
    "            epoch, G_AB, G_BA, D_A, D_B, \n",
    "            optimizer_G, optimizer_D_A, optimizer_D_B,\n",
    "            scheduler_G, scheduler_D_A, scheduler_D_B,\n",
    "            history, best_loss\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro durante treinamento: {e}\")\n",
    "        save_checkpoint_robust(\n",
    "            epoch, G_AB, G_BA, D_A, D_B, \n",
    "            optimizer_G, optimizer_D_A, optimizer_D_B,\n",
    "            scheduler_G, scheduler_D_A, scheduler_D_B,\n",
    "            history, best_loss\n",
    "        )\n",
    "        raise e\n",
    "    \n",
    "    # Finaliza√ß√£o\n",
    "    total_time = time.time() - total_start_time\n",
    "    total_hours = total_time / 3600\n",
    "    \n",
    "    print(f\"\\nüéâ TREINAMENTO CONCLU√çDO!\")\n",
    "    print(f\"‚è±Ô∏è Tempo total: {total_hours:.2f} horas\")\n",
    "    print(f\"üìà Melhor Generator Loss: {best_loss:.4f}\")\n",
    "    print(f\"üíæ Modelos salvos em: {config.MODEL_SAVE_PATH}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3b24d",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# FUN√á√ÉO PRINCIPAL\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se dataset existe\n",
    "if not os.path.exists(config.DATASET_PATH):\n",
    "    print(f\"‚ùå Dataset n√£o encontrado em {config.DATASET_PATH}\")\n",
    "    print(\"üí° Execute primeiro o notebook 'organize_datasets.ipynb'\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset encontrado: {config.DATASET_PATH}\")\n",
    "    print(f\"üéØ Treinando modelo baseline CycleGAN\")\n",
    "    \n",
    "    # Iniciar treinamento\n",
    "    history = train_cyclegan()\n",
    "    \n",
    "    # Plotar gr√°ficos de loss\n",
    "    if history and len(history['G_loss']) > 0:\n",
    "        # Plotar gr√°ficos de loss\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history['G_loss'], label='Generator Loss')\n",
    "        plt.title('Generator Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history['D_A_loss'], label='Discriminator A')\n",
    "        plt.plot(history['D_B_loss'], label='Discriminator B')\n",
    "        plt.title('Discriminator Losses')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(history['cycle_loss'], label='Cycle Loss')\n",
    "        plt.plot(history['adv_loss'], label='Adversarial Loss')\n",
    "        plt.title('Component Losses')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{config.MODEL_SAVE_PATH}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "\n",
    "        print(f\"üìä Gr√°ficos salvos em: {config.MODEL_SAVE_PATH}/training_curves.png\")\n",
    "        plt.close()  # ‚Üê Fechar figura para liberar mem√≥ria\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Sem dados suficientes para plotar gr√°ficos\")\n",
    "\n",
    "# ================================\n",
    "# DIAGN√ìSTICO DO PROBLEMA DE VISUALIZA√á√ÉO\n",
    "# ================================\n",
    "\n",
    "def test_visualization_issue():\n",
    "    \"\"\"Testar se problema de visualiza√ß√£o √© train vs eval mode\"\"\"\n",
    "    print(\"üîç DIAGN√ìSTICO: Testando diferen√ßa train vs eval mode...\")\n",
    "    \n",
    "    try:\n",
    "        # Verificar se modelos existem\n",
    "        if 'G_AB' not in globals() or 'G_BA' not in globals():\n",
    "            print(\"‚ùå Modelos n√£o encontrados. Execute o treinamento primeiro.\")\n",
    "            return\n",
    "        \n",
    "        # Pegar um batch pequeno de teste\n",
    "        if len(test_loader) == 0:\n",
    "            print(\"‚ùå Test loader vazio.\")\n",
    "            return\n",
    "            \n",
    "        test_batch = next(iter(test_loader))\n",
    "        real_A = test_batch['A'][:1].to(config.DEVICE)  # S√≥ 1 imagem\n",
    "        real_B = test_batch['B'][:1].to(config.DEVICE)\n",
    "        \n",
    "        print(f\"‚úÖ Usando imagem de teste: {real_A.shape}\")\n",
    "        \n",
    "        # TESTE 1: Gera√ß√£o em modo TRAIN\n",
    "        G_AB.train()\n",
    "        G_BA.train()\n",
    "        with torch.no_grad():\n",
    "            fake_B_train = G_AB(real_A)\n",
    "            fake_A_train = G_BA(real_B)\n",
    "        \n",
    "        # TESTE 2: Gera√ß√£o em modo EVAL\n",
    "        G_AB.eval()\n",
    "        G_BA.eval()\n",
    "        with torch.no_grad():\n",
    "            fake_B_eval = G_AB(real_A)\n",
    "            fake_A_eval = G_BA(real_B)\n",
    "        \n",
    "        # Voltar para train mode\n",
    "        G_AB.train()\n",
    "        G_BA.train()\n",
    "        \n",
    "        # Calcular diferen√ßas\n",
    "        diff_A2B = torch.abs(fake_B_train - fake_B_eval).mean().item()\n",
    "        diff_B2A = torch.abs(fake_A_train - fake_A_eval).mean().item()\n",
    "        \n",
    "        print(f\"\\nüìä RESULTADOS DO DIAGN√ìSTICO:\")\n",
    "        print(f\"   Diferen√ßa A‚ÜíB (train vs eval): {diff_A2B:.6f}\")\n",
    "        print(f\"   Diferen√ßa B‚ÜíA (train vs eval): {diff_B2A:.6f}\")\n",
    "        \n",
    "        # Interpretar resultados\n",
    "        threshold = 0.01  # Threshold para considerar \"diferen√ßa significativa\"\n",
    "        \n",
    "        if diff_A2B > threshold or diff_B2A > threshold:\n",
    "            print(f\"\\n‚úÖ CONFIRMADO: Problema √© train/eval mode!\")\n",
    "            print(f\"   üí° Solu√ß√£o: Usar .eval() mode para visualiza√ß√£o\")\n",
    "            diagnosis = \"train_eval_mode\"\n",
    "        else:\n",
    "            print(f\"\\n‚ùå N√ÉO √© train/eval mode. Investigar outras causas:\")\n",
    "            print(f\"   üí° Poss√≠veis causas: noise, batch norm, dropout, etc.\")\n",
    "            diagnosis = \"other_cause\"\n",
    "        \n",
    "        # Salvar compara√ß√£o visual para an√°lise\n",
    "        os.makedirs(f\"{config.MODEL_SAVE_PATH}/debug\", exist_ok=True)\n",
    "        \n",
    "        # Grid de compara√ß√£o: [Real | Train_mode | Eval_mode]\n",
    "        comparison_A2B = torch.cat([\n",
    "            real_A[0], fake_B_train[0], fake_B_eval[0]\n",
    "        ], dim=2)  # Horizontal\n",
    "        \n",
    "        comparison_B2A = torch.cat([\n",
    "            real_B[0], fake_A_train[0], fake_A_eval[0]\n",
    "        ], dim=2)  # Horizontal\n",
    "        \n",
    "        # Grid vertical\n",
    "        full_comparison = torch.cat([comparison_A2B, comparison_B2A], dim=1)\n",
    "        \n",
    "        debug_path = f\"{config.MODEL_SAVE_PATH}/debug/diagnosis_train_vs_eval.png\"\n",
    "        save_image(full_comparison, debug_path, normalize=True, value_range=(-1, 1))\n",
    "        \n",
    "        print(f\"\\nüíæ Compara√ß√£o visual salva em:\")\n",
    "        print(f\"   {debug_path}\")\n",
    "        print(f\"   Layout: [Real | Train_mode | Eval_mode]\")\n",
    "        print(f\"   Top row: A‚ÜíB, Bottom row: B‚ÜíA\")\n",
    "        \n",
    "        return diagnosis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro durante diagn√≥stico: {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "# EXECUTAR O DIAGN√ìSTICO (se modelos j√° estiverem treinados)\n",
    "if 'G_AB' in globals() and 'test_loader' in globals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üî¨ EXECUTANDO DIAGN√ìSTICO AUTOM√ÅTICO\")\n",
    "    print(\"=\"*50)\n",
    "    diagnosis_result = test_visualization_issue()\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Diagn√≥stico dispon√≠vel ap√≥s treinamento. Execute: test_visualization_issue()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a1337",
   "metadata": {},
   "source": [
    "# ================================\n",
    "# M√©tricas\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1429545",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config  # ‚Üê Garantir que config esteja acess√≠vel\n",
    "\n",
    "def evaluate_existing_models(num_samples=100):\n",
    "    \"\"\"\n",
    "    Avalia√ß√£o usando G_AB, G_BA, test_loader e config j√° existentes\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ AVALIA√á√ÉO QUANTITATIVA\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìä Configura√ß√£o:\")\n",
    "    print(f\"   Device: {config.DEVICE}\")\n",
    "    print(f\"   Samples: {num_samples}\")\n",
    "    print(f\"   Test dataset: {len(test_dataset)} amostras\")\n",
    "    \n",
    "    # Verificar se modelos existem\n",
    "    try:\n",
    "        print(f\"   G_AB status: {type(G_AB).__name__}\")\n",
    "        print(f\"   G_BA status: {type(G_BA).__name__}\")\n",
    "        print(f\"   Test loader: {len(test_loader)} batches\")\n",
    "    except NameError as e:\n",
    "        print(f\"‚ùå Erro: {e}\")\n",
    "        print(\"üí° Execute primeiro o notebook de treinamento\")\n",
    "        return None\n",
    "    \n",
    "    # Colocar modelos em modo avalia√ß√£o\n",
    "    G_AB.eval()\n",
    "    G_BA.eval()\n",
    "    \n",
    "    print(f\"\\nüîÑ Gerando {num_samples} amostras para avalia√ß√£o...\")\n",
    "    \n",
    "    # Listas para armazenar amostras\n",
    "    real_A_samples = []\n",
    "    real_B_samples = []\n",
    "    fake_A_samples = []\n",
    "    fake_B_samples = []\n",
    "    cycle_A_samples = []\n",
    "    cycle_B_samples = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "                \n",
    "            real_A = batch['A'].to(config.DEVICE)\n",
    "            real_B = batch['B'].to(config.DEVICE)\n",
    "            \n",
    "            # Transforma√ß√µes A‚ÜíB e B‚ÜíA\n",
    "            fake_B = G_AB(real_A)  # Real ‚Üí Cartoon\n",
    "            fake_A = G_BA(real_B)  # Cartoon ‚Üí Real\n",
    "            \n",
    "            # Cycles A‚ÜíB‚ÜíA e B‚ÜíA‚ÜíB\n",
    "            cycle_A = G_BA(fake_B)  # Real ‚Üí Cartoon ‚Üí Real\n",
    "            cycle_B = G_AB(fake_A)  # Cartoon ‚Üí Real ‚Üí Cartoon\n",
    "            \n",
    "            # Armazenar samples (CPU para economizar VRAM)\n",
    "            batch_size = real_A.size(0)\n",
    "            for i in range(min(batch_size, num_samples - count)):\n",
    "                real_A_samples.append(real_A[i].cpu())\n",
    "                real_B_samples.append(real_B[i].cpu())\n",
    "                fake_A_samples.append(fake_A[i].cpu())\n",
    "                fake_B_samples.append(fake_B[i].cpu())\n",
    "                cycle_A_samples.append(cycle_A[i].cpu())\n",
    "                cycle_B_samples.append(cycle_B[i].cpu())\n",
    "                count += 1\n",
    "            \n",
    "            # Progress update\n",
    "            if batch_idx % 5 == 0:\n",
    "                progress = (count / num_samples) * 100\n",
    "                print(f\"   Progresso: {count}/{num_samples} ({progress:.1f}%)\")\n",
    "    \n",
    "    print(f\"‚úÖ {count} amostras geradas com sucesso!\")\n",
    "    \n",
    "    return {\n",
    "        'real_A': real_A_samples,\n",
    "        'real_B': real_B_samples,\n",
    "        'fake_A': fake_A_samples,\n",
    "        'fake_B': fake_B_samples,\n",
    "        'cycle_A': cycle_A_samples,\n",
    "        'cycle_B': cycle_B_samples,\n",
    "        'count': count\n",
    "    }\n",
    "\n",
    "def calculate_metrics(samples):\n",
    "    \"\"\"Calcular todas as m√©tricas de avalia√ß√£o\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä CALCULANDO M√âTRICAS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    \n",
    "    # 1. CYCLE CONSISTENCY (m√©trica principal do CycleGAN)\n",
    "    print(\"üîÑ Cycle Consistency...\")\n",
    "    \n",
    "    cycle_loss_A = 0  # A ‚Üí B ‚Üí A\n",
    "    cycle_loss_B = 0  # B ‚Üí A ‚Üí B\n",
    "    \n",
    "    for real_A, cycle_A in zip(samples['real_A'], samples['cycle_A']):\n",
    "        cycle_loss_A += l1_loss(real_A, cycle_A).item()\n",
    "    \n",
    "    for real_B, cycle_B in zip(samples['real_B'], samples['cycle_B']):\n",
    "        cycle_loss_B += l1_loss(real_B, cycle_B).item()\n",
    "    \n",
    "    num_samples = samples['count']\n",
    "    avg_cycle_A = cycle_loss_A / num_samples\n",
    "    avg_cycle_B = cycle_loss_B / num_samples\n",
    "    avg_cycle_total = (cycle_loss_A + cycle_loss_B) / (2 * num_samples)\n",
    "    \n",
    "    print(f\"   A‚ÜíB‚ÜíA: {avg_cycle_A:.4f}\")\n",
    "    print(f\"   B‚ÜíA‚ÜíB: {avg_cycle_B:.4f}\")\n",
    "    print(f\"   M√©dia: {avg_cycle_total:.4f}\")\n",
    "    \n",
    "    # 2. PIXEL-LEVEL SIMILARITY (L1 e MSE)\n",
    "    print(\"üñºÔ∏è Pixel-level metrics...\")\n",
    "    \n",
    "    # L1 entre transforma√ß√µes\n",
    "    l1_A_to_B = 0\n",
    "    l1_B_to_A = 0\n",
    "    mse_A_to_B = 0\n",
    "    mse_B_to_A = 0\n",
    "    \n",
    "    for real_A, fake_B in zip(samples['real_A'], samples['fake_B']):\n",
    "        l1_A_to_B += l1_loss(real_A, fake_B).item()\n",
    "        mse_A_to_B += mse_loss(real_A, fake_B).item()\n",
    "    \n",
    "    for real_B, fake_A in zip(samples['real_B'], samples['fake_A']):\n",
    "        l1_B_to_A += l1_loss(real_B, fake_A).item()\n",
    "        mse_B_to_A += mse_loss(real_B, fake_A).item()\n",
    "    \n",
    "    avg_l1_A_to_B = l1_A_to_B / num_samples\n",
    "    avg_l1_B_to_A = l1_B_to_A / num_samples\n",
    "    avg_mse_A_to_B = mse_A_to_B / num_samples\n",
    "    avg_mse_B_to_A = mse_B_to_A / num_samples\n",
    "    \n",
    "    print(f\"   L1 A‚ÜíB: {avg_l1_A_to_B:.4f}\")\n",
    "    print(f\"   L1 B‚ÜíA: {avg_l1_B_to_A:.4f}\")\n",
    "    print(f\"   MSE A‚ÜíB: {avg_mse_A_to_B:.4f}\")\n",
    "    print(f\"   MSE B‚ÜíA: {avg_mse_B_to_A:.4f}\")\n",
    "    \n",
    "    # 3. IDENTITY PRESERVATION (se aplic√°vel)\n",
    "    print(\"üéØ Identity metrics...\")\n",
    "    \n",
    "    # Measure of how different A‚ÜíB and B‚ÜíA are (domain transfer effectiveness)\n",
    "    domain_transfer_A_to_B = avg_l1_A_to_B  # Higher = more transformation\n",
    "    domain_transfer_B_to_A = avg_l1_B_to_A\n",
    "    \n",
    "    print(f\"   Domain transfer A‚ÜíB: {domain_transfer_A_to_B:.4f}\")\n",
    "    print(f\"   Domain transfer B‚ÜíA: {domain_transfer_B_to_A:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'cycle_consistency': {\n",
    "            'A_to_B_to_A': avg_cycle_A,\n",
    "            'B_to_A_to_B': avg_cycle_B,\n",
    "            'average': avg_cycle_total\n",
    "        },\n",
    "        'pixel_similarity': {\n",
    "            'L1_A_to_B': avg_l1_A_to_B,\n",
    "            'L1_B_to_A': avg_l1_B_to_A,\n",
    "            'MSE_A_to_B': avg_mse_A_to_B,\n",
    "            'MSE_B_to_A': avg_mse_B_to_A\n",
    "        },\n",
    "        'domain_transfer': {\n",
    "            'A_to_B_effectiveness': domain_transfer_A_to_B,\n",
    "            'B_to_A_effectiveness': domain_transfer_B_to_A,\n",
    "            'asymmetry_ratio': domain_transfer_B_to_A / domain_transfer_A_to_B\n",
    "        }\n",
    "    }\n",
    "\n",
    "def compare_with_literature(metrics):\n",
    "    \"\"\"Comparar resultados com papers publicados\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìà COMPARA√á√ÉO COM LITERATURA\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    cycle_consistency = metrics['cycle_consistency']['average']\n",
    "    \n",
    "    # Baselines de papers conhecidos (valores aproximados)\n",
    "    baselines = {\n",
    "        'CycleGAN Original (Zhu et al., 2017)': {\n",
    "            'cycle_consistency': 0.15,\n",
    "            'domain': 'horse2zebra, apple2orange'\n",
    "        },\n",
    "        'AttentionGAN (Tang et al., 2019)': {\n",
    "            'cycle_consistency': 0.12,\n",
    "            'domain': 'face translation'\n",
    "        },\n",
    "        'UNIT (Liu et al., 2017)': {\n",
    "            'cycle_consistency': 0.18,\n",
    "            'domain': 'various'\n",
    "        },\n",
    "        'Pix2Pix (Isola et al., 2017) - supervised': {\n",
    "            'cycle_consistency': 0.05,\n",
    "            'domain': 'paired data'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"üéØ SEU MODELO:\")\n",
    "    print(f\"   Cycle Consistency: {cycle_consistency:.4f}\")\n",
    "    print(f\"   Domain: Real ‚Üî Cartoon (unpaired)\")\n",
    "    print(f\"   M√©todo: CycleGAN + LSGAN + Spectral Norm + TTUR\")\n",
    "    \n",
    "    print(f\"\\nüìä BASELINES PUBLICADOS:\")\n",
    "    \n",
    "    your_rank = 1\n",
    "    better_than = []\n",
    "    worse_than = []\n",
    "    \n",
    "    for method, data in baselines.items():\n",
    "        baseline_value = data['cycle_consistency']\n",
    "        \n",
    "        if cycle_consistency <= baseline_value:\n",
    "            status = \"‚úÖ SUPERIOR\"\n",
    "            better_than.append(method)\n",
    "        else:\n",
    "            status = \"‚ö†Ô∏è inferior\"\n",
    "            worse_than.append(method)\n",
    "            your_rank += 1\n",
    "        \n",
    "        print(f\"   {status} {method}:\")\n",
    "        print(f\"      Cycle: {baseline_value:.4f} | Domain: {data['domain']}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ POSI√á√ÉO: {your_rank}/{len(baselines)+1}\")\n",
    "    \n",
    "    # An√°lise qualitativa\n",
    "    if cycle_consistency <= 0.08:\n",
    "        quality = \"üéâ EXCEPCIONAL! N√≠vel state-of-the-art!\"\n",
    "    elif cycle_consistency <= 0.12:\n",
    "        quality = \"üèÜ EXCELENTE! Competitivo com os melhores papers!\"\n",
    "    elif cycle_consistency <= 0.15:\n",
    "        quality = \"‚úÖ MUITO BOM! Compar√°vel ao CycleGAN original!\"\n",
    "    elif cycle_consistency <= 0.20:\n",
    "        quality = \"üëç BOM! Resultado aceit√°vel para research!\"\n",
    "    else:\n",
    "        quality = \"‚ö†Ô∏è MODERADO. Margem para melhoria.\"\n",
    "    \n",
    "    print(f\"\\n{quality}\")\n",
    "    \n",
    "    if better_than:\n",
    "        print(f\"‚úÖ Superior a: {len(better_than)} m√©todo(s)\")\n",
    "    if worse_than:\n",
    "        print(f\"‚ö†Ô∏è Inferior a: {len(worse_than)} m√©todo(s)\")\n",
    "    \n",
    "    return {\n",
    "        'rank': your_rank,\n",
    "        'total_methods': len(baselines) + 1,\n",
    "        'better_than': better_than,\n",
    "        'worse_than': worse_than,\n",
    "        'quality_assessment': quality\n",
    "    }\n",
    "\n",
    "def save_evaluation_results(samples, metrics, comparison, model_info=None):\n",
    "    \"\"\"Salvar todos os resultados da avalia√ß√£o\"\"\"\n",
    "    \n",
    "    print(f\"\\nüíæ SALVANDO RESULTADOS\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Compilar todos os resultados\n",
    "    results = {\n",
    "        'metadata': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'evaluation_type': 'quantitative_analysis',\n",
    "            'num_samples': samples['count'],\n",
    "            'model_path': config.MODEL_SAVE_PATH,\n",
    "            'device': str(config.DEVICE)\n",
    "        },\n",
    "        'model_configuration': {\n",
    "            'lambda_cycle': config.LAMBDA_CYCLE,\n",
    "            'lambda_identity': config.LAMBDA_IDENTITY,\n",
    "            'lr_g': config.LR_G,\n",
    "            'lr_d': config.LR_D,\n",
    "            'num_residual_blocks': config.NUM_RESIDUAL_BLOCKS,\n",
    "            'use_spectral_norm': True,\n",
    "            'use_ttur': True,\n",
    "            'use_lsgan': True,\n",
    "            'architecture_improvements': [\n",
    "                'Spectral Normalization',\n",
    "                'TTUR Learning Rates', \n",
    "                'Upsample + Conv (no deconvolution)',\n",
    "                'Label Smoothing',\n",
    "                'Reflection Padding'\n",
    "            ]\n",
    "        },\n",
    "        'quantitative_metrics': metrics,\n",
    "        'literature_comparison': comparison\n",
    "    }\n",
    "    \n",
    "    # Salvar em JSON\n",
    "    results_path = f\"{config.MODEL_SAVE_PATH}/quantitative_evaluation.json\"\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ Resultados salvos em:\")\n",
    "    print(f\"   {results_path}\")\n",
    "    \n",
    "    # Criar relat√≥rio de texto simples\n",
    "    report_path = f\"{config.MODEL_SAVE_PATH}/evaluation_report.txt\"\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"RELAT√ìRIO DE AVALIA√á√ÉO QUANTITATIVA\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Amostras avaliadas: {samples['count']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"M√âTRICAS PRINCIPAIS:\\n\")\n",
    "        f.write(f\"Cycle Consistency: {metrics['cycle_consistency']['average']:.4f}\\n\")\n",
    "        f.write(f\"L1 A‚ÜíB: {metrics['pixel_similarity']['L1_A_to_B']:.4f}\\n\")\n",
    "        f.write(f\"L1 B‚ÜíA: {metrics['pixel_similarity']['L1_B_to_A']:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"POSI√á√ÉO NA LITERATURA: {comparison['rank']}/{comparison['total_methods']}\\n\")\n",
    "        f.write(f\"Superior a {len(comparison['better_than'])} m√©todo(s)\\n\")\n",
    "        f.write(f\"Avalia√ß√£o: {comparison['quality_assessment']}\\n\")\n",
    "    \n",
    "    print(f\"üìÑ Relat√≥rio de texto salvo em:\")\n",
    "    print(f\"   {report_path}\")\n",
    "    \n",
    "    return results_path\n",
    "\n",
    "def run_complete_evaluation():\n",
    "    \"\"\"FUN√á√ÉO PRINCIPAL - Execute esta para avalia√ß√£o completa\"\"\"\n",
    "    \n",
    "    print(\"üéØ AVALIA√á√ÉO QUANTITATIVA COMPLETA\")\n",
    "    print(\"üî¨ CycleGAN Real2Cartoon - An√°lise Final\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Gerar amostras usando modelos existentes\n",
    "        samples = evaluate_existing_models(num_samples=100)\n",
    "        if samples is None:\n",
    "            return None\n",
    "        \n",
    "        # 2. Calcular m√©tricas quantitativas\n",
    "        metrics = calculate_metrics(samples)\n",
    "        \n",
    "        # 3. Comparar com literatura\n",
    "        comparison = compare_with_literature(metrics)\n",
    "        \n",
    "        # 4. Salvar resultados\n",
    "        results_path = save_evaluation_results(samples, metrics, comparison)\n",
    "        \n",
    "        print(f\"\\nüéâ AVALIA√á√ÉO COMPLETA CONCLU√çDA!\")\n",
    "        print(f\"üìä Cycle Consistency: {metrics['cycle_consistency']['average']:.4f}\")\n",
    "        print(f\"üèÜ Ranking: {comparison['rank']}/{comparison['total_methods']}\")\n",
    "        print(f\"üíæ Resultados: {results_path}\")\n",
    "        \n",
    "        return {\n",
    "            'samples': samples,\n",
    "            'metrics': metrics,\n",
    "            'comparison': comparison,\n",
    "            'results_path': results_path\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro durante avalia√ß√£o: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bea288",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = run_complete_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CG_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
