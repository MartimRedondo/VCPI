{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38936dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "from src.constants import device, BATCH_SIZE, WORKERS, PREFETCH\n",
    "from src.models import ModernCNN, ImprovedCNN, EfficientCNN, AttentionCNN, evaluate_model\n",
    "from src.transformations import test_transform, train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee06d7f",
   "metadata": {},
   "source": [
    "## 1 - Carregamento de Modelos Pré-treinados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba5d52",
   "metadata": {},
   "source": [
    "#### Parâmetro\n",
    "\n",
    "    • model_path: Caminho para o ficheiro de checkpoint do modelo pré-treinado.\n",
    "\n",
    "Carrega o resultado de um modelo pré-treinado a partir de um ficheiro de checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a082677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model_type = checkpoint['model_type']\n",
    "    num_classes = checkpoint['num_classes']\n",
    "\n",
    "    if model_type == 'AttentionCNN':\n",
    "        model = AttentionCNN(num_classes=num_classes)\n",
    "    elif model_type == 'EfficientCNN':\n",
    "        model = EfficientCNN(num_classes=num_classes)\n",
    "    elif model_type == 'ImprovedCNN':\n",
    "        model = ImprovedCNN(num_classes=num_classes)\n",
    "    elif model_type == 'ModernCNN':\n",
    "        model = ModernCNN(num_classes=num_classes) \n",
    "    else:\n",
    "        raise ValueError(f\"Modelo desconhecido: '{model_type}'\")\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404384b",
   "metadata": {},
   "source": [
    "## 2 - Preparação de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba06000",
   "metadata": {},
   "source": [
    "#### Estrutura e Configuração\n",
    "\n",
    "    • Configuração do conjunto de treino\n",
    "\n",
    "    • Configuração do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9c06859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franc/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with augmentations\n",
    "data_path = 'data/'  # Path to the data folder\n",
    "\n",
    "# Load training dataset with augmentation\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path + 'train_images',\n",
    "    transform=train_transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path + 'test_images',\n",
    "    transform=test_transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f118a5",
   "metadata": {},
   "source": [
    "## 3 - Definição de Modelos por Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac377c",
   "metadata": {},
   "source": [
    "#### Estrutura e Organização\n",
    "\n",
    "1. **Organização por tipo de augmentation**:\n",
    "   - Seis configurações distintas são definidas: advanced, aggressive, color, default, basic, geometric\n",
    "   - Cada configuração corresponde a uma estratégia específica de data augmentation utilizada durante o treino dos modelos\n",
    "   - Esta organização permite avaliar o impacto de diferentes técnicas de augmentation no desempenho dos ensembles\n",
    "\n",
    "2. **Consistência arquitetural**:\n",
    "   - Para cada configuração, são incluídas as mesmas quatro arquiteturas: AttentionCNN, EfficientCNN, ImprovedCNN, ModernCNN\n",
    "   - Esta consistência permite comparações diretas entre diferentes configurações de augmentation\n",
    "   - A ordem das arquiteturas é mantida consistente em todas as listas, facilitando o processamento\n",
    "\n",
    "3. **Uso de ficheiro `.pt`**:\n",
    "   - O sufixo `.pt` indica que são ficheiros de checkpoint PyTorch\n",
    "\n",
    "4. **Constante N_MODELS**:\n",
    "   - Define explicitamente o número de modelos em cada configuração (4)\n",
    "   - Esta constante será utilizada posteriormente para iterações e indexação\n",
    "   - A definição explícita melhora a manutenibilidade do código, evitando números mágicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c438578",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_advanced = [\n",
    "    \"results/AttentionCNN_advanced.pt\",\n",
    "    \"results/EfficientCNN_advanced.pt\",\n",
    "    \"results/ImprovedCNN_advanced.pt\",\n",
    "    \"results/ModernCNN_advanced.pt\",\n",
    "]\n",
    "models_aggressive = [\n",
    "    \"results/AttentionCNN_aggressive.pt\",\n",
    "    \"results/EfficientCNN_aggressive.pt\",\n",
    "    \"results/ImprovedCNN_aggressive.pt\",\n",
    "    \"results/ModernCNN_aggressive.pt\",\n",
    "]\n",
    "models_color = [\n",
    "    \"results/AttentionCNN_color.pt\",\n",
    "    \"results/EfficientCNN_color.pt\",\n",
    "    \"results/ImprovedCNN_color.pt\",\n",
    "    \"results/ModernCNN_color.pt\",\n",
    "]\n",
    "\n",
    "models_default = [\n",
    "    \"results/AttentionCNN_default.pt\",\n",
    "    \"results/EfficientCNN_default.pt\",\n",
    "    \"results/ImprovedCNN_default.pt\",\n",
    "    \"results/ModernCNN_default.pt\",\n",
    "]\n",
    "\n",
    "models_basic = [\n",
    "    \"results/AttentionCNN_basic.pt\",\n",
    "    \"results/EfficientCNN_basic.pt\",\n",
    "    \"results/ImprovedCNN_basic.pt\",\n",
    "    \"results/ModernCNN_basic.pt\",\n",
    "]\n",
    "\n",
    "models_geometric = [\n",
    "    \"results/AttentionCNN_geometric.pt\",\n",
    "    \"results/EfficientCNN_geometric.pt\",\n",
    "    \"results/ImprovedCNN_geometric.pt\",\n",
    "    \"results/ModernCNN_geometric.pt\",\n",
    "]\n",
    "\n",
    "N_MODELS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591fe3b",
   "metadata": {},
   "source": [
    "## 4 - Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea113226",
   "metadata": {},
   "source": [
    "#### Load de todos os modelos para cada augmetation.\n",
    "\n",
    "#### Cálculo da accuracy de todos os modelo para cada augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8865867",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models_advanced = [load_trained_model(path) for path in models_advanced]\n",
    "acc_advanced = [evaluate_model(model, test_loader) for model in loaded_models_advanced]\n",
    "\n",
    "loaded_models_aggressive = [load_trained_model(path) for path in models_aggressive]\n",
    "acc_aggressive = [evaluate_model(model, test_loader) for model in loaded_models_aggressive]\n",
    "\n",
    "loaded_models_color = [load_trained_model(path) for path in models_color]\n",
    "acc_color = [evaluate_model(model, test_loader) for model in loaded_models_color]\n",
    "\n",
    "loaded_models_basic = [load_trained_model(path) for path in models_basic]\n",
    "acc_basic = [evaluate_model(model, test_loader) for model in loaded_models_basic]\n",
    "\n",
    "loaded_models_default = [load_trained_model(path) for path in models_default]\n",
    "acc_default = [evaluate_model(model, test_loader) for model in loaded_models_default]\n",
    "\n",
    "loaded_models_geometric = [load_trained_model(path) for path in models_geometric]\n",
    "acc_geometric = [evaluate_model(model, test_loader) for model in loaded_models_geometric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b48a33",
   "metadata": {},
   "source": [
    "## 5 - Get Labels, Predictions and Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa4113d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_logits_and_preds(models):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = [[] for _ in range(N_MODELS)]\n",
    "        labels = []\n",
    "\n",
    "        for images, labs in test_loader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels.extend(labs)\n",
    "            \n",
    "            for i in range(N_MODELS):\n",
    "                logits[i].extend(models[i](images).cpu())\n",
    "\n",
    "\n",
    "    return labels, logits\n",
    "\n",
    "labels_advanced, logits_advanced = get_labels_logits_and_preds(loaded_models_advanced)\n",
    "labels_aggressive, logits_aggressive = get_labels_logits_and_preds(loaded_models_aggressive)\n",
    "labels_color, logits_color = get_labels_logits_and_preds(loaded_models_color)\n",
    "labels_basic, logits_basic = get_labels_logits_and_preds(loaded_models_basic)\n",
    "labels_default, logits_default = get_labels_logits_and_preds(loaded_models_default)\n",
    "labels_geometric, logits_geometric = get_labels_logits_and_preds(loaded_models_geometric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbe62c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_advanced = [[] for _ in range(len(labels_advanced))]\n",
    "preds_aggressive = [[] for _ in range(len(labels_aggressive))]\n",
    "preds_color = [[] for _ in range(len(labels_color))]\n",
    "preds_basic = [[] for _ in range(len(labels_basic))]\n",
    "preds_default = [[] for _ in range(len(labels_default))]\n",
    "preds_geometric = [[] for _ in range(len(labels_geometric))]\n",
    "\n",
    "for index in range(len(labels_advanced)):\n",
    "    preds_advanced[index] = [np.argmax(logits_advanced[m][index].cpu().numpy()) for m in range(N_MODELS)]\n",
    "    preds_aggressive[index] = [np.argmax(logits_aggressive[m][index].cpu().numpy()) for m in range(N_MODELS)]\n",
    "    preds_color[index] = [np.argmax(logits_color[m][index].cpu().numpy()) for m in range(N_MODELS)]\n",
    "    preds_basic[index] = [np.argmax(logits_basic[m][index].cpu().numpy()) for m in range(N_MODELS)]\n",
    "    preds_default[index] = [np.argmax(logits_default[m][index].cpu().numpy()) for m in range(N_MODELS)]\n",
    "    preds_geometric[index] = [np.argmax(logits_geometric[m][index].cpu().numpy()) for m in range(N_MODELS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4e5a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8272/2550373045.py:9: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  log = np.add(log, logits[m][i])\n"
     ]
    }
   ],
   "source": [
    "def get_class_from_sum_of_logits(logits):\n",
    "\n",
    "    sum_logits = []\n",
    "\n",
    "    for i in range(len(logits[0])):\n",
    "\n",
    "        log = logits[0][i]\n",
    "        for m in range(1, N_MODELS):\n",
    "            log = np.add(log, logits[m][i])\n",
    "        sum_logits.append(np.argmax(log))\n",
    "    return(sum_logits)\n",
    "    \n",
    "class_logits_advanced = get_class_from_sum_of_logits(logits_advanced)\n",
    "class_logits_aggressive = get_class_from_sum_of_logits(logits_aggressive)\n",
    "class_logits_color = get_class_from_sum_of_logits(logits_color)\n",
    "class_logits_basic = get_class_from_sum_of_logits(logits_basic)\n",
    "class_logits_default = get_class_from_sum_of_logits(logits_default)\n",
    "class_logits_geometric = get_class_from_sum_of_logits(logits_geometric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc27b2",
   "metadata": {},
   "source": [
    "## 6 - Voto majoritário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e2a2d",
   "metadata": {},
   "source": [
    "#### Usa as previsões de cada modelo para avaliar os resultados da aplicação do conjunto de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453d727",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69645f",
   "metadata": {},
   "source": [
    "#### Voto Majoritário:\n",
    "\n",
    "    - Se mais de metade dos modelos acertar a previsão, então é considerado um acerto para o resultado final;\n",
    "    \n",
    "    - Se mais de metade dos modelos errar a previsão, então é considerado um erro para o resultado final;\n",
    "\n",
    "    - Em caso de empate, então é considerado um erro para o resultado final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad787872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(labels, class_preds, class_logits):\n",
    "\n",
    "    all_correct = 0\n",
    "    all_incorrect = 0\n",
    "    maj_vote = 0\n",
    "    maj_wrong = 0\n",
    "    tie = 0\n",
    "    count = 0\n",
    "\n",
    "    for k in range(len(labels)):\n",
    "\n",
    "        counter = collections.Counter(class_preds[k])\n",
    "        if len(counter) == 1:\n",
    "            if counter.most_common(1)[0][0] == labels[k]:\n",
    "                all_correct += 1\n",
    "            else:\n",
    "                all_incorrect += 1\n",
    "        else:\n",
    "            aux = counter.most_common(2)\n",
    "            if aux[0][1] > aux[1][1] and aux[0][0] == labels[k]:\n",
    "                maj_vote += 1\n",
    "            if aux[0][1] > aux[1][1] and aux[0][0] != labels[k]:\n",
    "                maj_wrong += 1\n",
    "            elif aux[0][1] == aux[1][1]:\n",
    "                tie += 1\n",
    "\n",
    "        count += 1 \n",
    "        \n",
    "    return [count, all_correct, all_incorrect, maj_vote, tie, maj_wrong]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ae0f2",
   "metadata": {},
   "source": [
    "## 7 - Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f533f",
   "metadata": {},
   "source": [
    "| Configuração | Acurácia | Melhor Aspecto |\n",
    "|--------------|----------|----------------|\n",
    "| Advanced     | 97.03%   | Maior consenso (92.3% concordância total) |\n",
    "| Color        | 97.05%   | Ligeiramente superior ao Advanced |\n",
    "| Basic        | 96.63%   | Boa performance com *augmentation* simples |\n",
    "| Geometric    | 95.46%   | Beneficia de transformações espaciais |\n",
    "| Default      | 94.89%   | *Baseline* sólido |\n",
    "| Aggressive   | 92.26%   | Maior diversidade, mais empates |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2d518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Advanced Argumentation Ensemble Results\n",
      "total:  12630\n",
      "All correct:  11664\n",
      "All incorrect:  79\n",
      "Majority correct:  591\n",
      "Tie Vote:  170\n",
      "Majority Wrong:  126\n",
      "Percentage right (all correct + majority correct):  0.9703087885985748\n",
      "================================================================================\n",
      "================================================================================\n",
      "Aggressive Argumentation Ensemble Results\n",
      "total:  12630\n",
      "All correct:  10391\n",
      "All incorrect:  188\n",
      "Majority correct:  1262\n",
      "Tie Vote:  394\n",
      "Majority Wrong:  395\n",
      "Percentage right (all correct + majority correct):  0.9226444972288202\n",
      "================================================================================\n",
      "================================================================================\n",
      "Color Argumentation Ensemble Results\n",
      "total:  12630\n",
      "All correct:  11664\n",
      "All incorrect:  72\n",
      "Majority correct:  593\n",
      "Tie Vote:  164\n",
      "Majority Wrong:  137\n",
      "Percentage right (all correct + majority correct):  0.9704671417260491\n",
      "================================================================================\n",
      "================================================================================\n",
      "Basic Argumentation Ensemble Results\n",
      "total:  12630\n",
      "All correct:  11481\n",
      "All incorrect:  84\n",
      "Majority correct:  724\n",
      "Tie Vote:  213\n",
      "Majority Wrong:  128\n",
      "Percentage right (all correct + majority correct):  0.9663499604117182\n",
      "================================================================================\n",
      "================================================================================\n",
      "Default Argumentation Ensemble Results\n",
      "total:  12630\n",
      "All correct:  10956\n",
      "All incorrect:  80\n",
      "Majority correct:  1028\n",
      "Tie Vote:  359\n",
      "Majority Wrong:  207\n",
      "Percentage right (all correct + majority correct):  0.9488519398258115\n",
      "================================================================================\n",
      "================================================================================\n",
      "Geometric Argumentation Ensemble Results\n",
      "total:  12630\n",
      "All correct:  11190\n",
      "All incorrect:  125\n",
      "Majority correct:  866\n",
      "Tie Vote:  241\n",
      "Majority Wrong:  208\n",
      "Percentage right (all correct + majority correct):  0.9545526524148852\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_stats(labels, class_preds, class_logits, type=\"Default\"):\n",
    "    res = get_stats(labels, class_preds, class_logits)\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{type} augmentation Ensemble Results\")\n",
    "    print('total: ', res[0])\n",
    "    print('All correct: ', res[1])\n",
    "    print('All incorrect: ', res[2])\n",
    "    print('Majority correct: ', res[3])\n",
    "    print('Tie Vote: ', res[4])\n",
    "    print('Majority Wrong: ', res[5])\n",
    "    print('Percentage right (all correct + majority correct): ', (res[1]+res[3])/res[0])\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print_stats(labels_advanced, preds_advanced, class_logits_advanced, type=\"Advanced\")\n",
    "print_stats(labels_aggressive, preds_aggressive, class_logits_aggressive, type=\"Aggressive\")\n",
    "print_stats(labels_color, preds_color, class_logits_color, type=\"Color\")\n",
    "print_stats(labels_basic, preds_basic, class_logits_basic, type=\"Basic\")\n",
    "print_stats(labels_default, preds_default, class_logits_default, type=\"Default\")\n",
    "print_stats(labels_geometric, preds_geometric, class_logits_geometric, type=\"Geometric\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
